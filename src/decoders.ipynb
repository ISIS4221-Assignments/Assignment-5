{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel, \n",
    "    GPT2Tokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración de dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Model definitions and loading:\n",
    "\n",
    "The decoder models to be used are:\n",
    "\n",
    "- GPT-2 (124M parameters)\n",
    "- GPT-2-XL (1.5B parameters)\n",
    "- Gemma2 (2B parameters)\n",
    "\n",
    "This section loads the models and defines the generation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --index-url https://download.pytorch.org/whl/cu121 torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers scikit-learn pandas numpy tqdm matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admonsis/.venv-1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 3 files: 100%|██████████| 3/3 [01:27<00:00, 29.27s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# === Gemma 2 (≤7B) setup via Hugging Face Transformers (PyTorch) ===\n",
    "# Requisitos:\n",
    "!pip install -U accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id = os.environ.get(\"GEMMA2_MODEL_ID\", \"google/gemma-2-2b\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "def gemma2_generate(prompt, max_new_tokens=128, temperature=0.7, top_p=0.95):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Functions (from the encoder notebook)\n",
    "\n",
    "These functions clean the texts by removing:\n",
    "\n",
    "* **20Newsgroups**: Email headers, email addresses, URLs, signatures, quoted lines\n",
    "* **Multi-Domain Sentiment**: Underscores, special tokens such as `<num>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_20_news(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans a 20 Newsgroups document by removing email metadata and artifacts.\n",
    "    \n",
    "    Steps:\n",
    "    1. Removes common email headers (From, Subject, Organization, etc.)\n",
    "    2. Deletes email addresses and URLs using regex\n",
    "    3. Removes signature lines and separators ('--', '__')\n",
    "    4. Removes quoted lines starting with '>' or ':'\n",
    "    5. Collapses multiple newlines and spaces for consistent formatting\n",
    "    \n",
    "    Args:\n",
    "        text: Raw email or newsgroup message text\n",
    "        \n",
    "    Returns:\n",
    "        Clean text containing only meaningful content\n",
    "    \"\"\"\n",
    "    # Remove common email headers\n",
    "    text = re.sub(r'^(From|Subject|Lines|Organization|Reply-To|NNTP-Posting-Host|Keywords|Summary):.*$', \n",
    "                  '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove email addresses and URLs\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove signature lines or separators\n",
    "    text = re.sub(r'--+\\s*$', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'_+', '', text)\n",
    "    \n",
    "    # Remove quoted lines (starting with > or :)\n",
    "    text = re.sub(r'(^>.*$|^:.*$)', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Collapse multiple newlines and spaces\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def clean_multidomain(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Simplifies review text from the Multi-Domain Sentiment dataset.\n",
    "    \n",
    "    Steps:\n",
    "    1. Replaces underscores with spaces to normalize tokens\n",
    "    2. Removes placeholder tokens like '<num>'\n",
    "    3. Eliminates redundant spaces\n",
    "    \n",
    "    Args:\n",
    "        text: Raw dataset text\n",
    "        \n",
    "    Returns:\n",
    "        Clean version of the text\n",
    "    \"\"\"\n",
    "    # Replace underscores with spaces\n",
    "    text = text.replace(\"_\", \" \")\n",
    "    \n",
    "    # Remove special tokens like <num>\n",
    "    text = re.sub(r\"<num>\", \"\", text)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Datasets with Preprocessing\n",
    "\n",
    "### 2.1 20Newsgroups Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsGroupsLoader:\n",
    "    \"\"\"\n",
    "    Class for loading and processing the 20Newsgroups dataset with enhanced cleaning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_path: str):\n",
    "        \"\"\"\n",
    "        Initializes the loader.\n",
    "        \n",
    "        Args:\n",
    "            root_path: Path to the dataset’s root directory\n",
    "        \"\"\"\n",
    "        self.root_path = Path(root_path)\n",
    "        self.categories = self._get_categories()\n",
    "        \n",
    "    def _get_categories(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the list of dataset categories.\n",
    "        \n",
    "        Returns:\n",
    "            Sorted list of category names\n",
    "        \"\"\"\n",
    "        categories = [d.name for d in self.root_path.iterdir() if d.is_dir()]\n",
    "        return sorted(categories)\n",
    "    \n",
    "    def load_data(self, max_samples_per_category: Optional[int] = None) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Loads dataset samples with automatic cleaning.\n",
    "        \n",
    "        Args:\n",
    "            max_samples_per_category: Maximum number of samples per category\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (clean_texts, labels)\n",
    "        \"\"\"\n",
    "        texts = []\n",
    "        labels = []\n",
    "        \n",
    "        print(f\"Loading 20Newsgroups from: {self.root_path}\")\n",
    "        print(f\"Categories found: {len(self.categories)}\")\n",
    "        \n",
    "        for category in tqdm(self.categories, desc=\"Processing categories\"):\n",
    "            category_path = self.root_path / category\n",
    "            files = list(category_path.glob('*'))\n",
    "            \n",
    "            if max_samples_per_category:\n",
    "                files = files[:max_samples_per_category]\n",
    "            \n",
    "            for file_path in files:\n",
    "                if file_path.is_file():\n",
    "                    try:\n",
    "                        # Read file with encoding handling\n",
    "                        with open(file_path, 'rb') as f:\n",
    "                            raw = f.read()\n",
    "                        \n",
    "                        try:\n",
    "                            text = raw.decode('utf-8').strip()\n",
    "                        except UnicodeDecodeError:\n",
    "                            text = raw.decode('latin-1').strip()\n",
    "                        \n",
    "                        # APPLY CLEANING\n",
    "                        cleaned_text = clean_20_news(text)\n",
    "                        \n",
    "                        # Only add if content remains after cleaning\n",
    "                        if cleaned_text and len(cleaned_text) > 50:\n",
    "                            texts.append(cleaned_text)\n",
    "                            labels.append(category)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_path}: {e}\")\n",
    "        \n",
    "        print(f\"\\nTotal loaded documents: {len(texts)}\")\n",
    "        print(f\"Category distribution:\")\n",
    "        label_counts = Counter(labels)\n",
    "        for label, count in sorted(label_counts.items()):\n",
    "            print(f\"  {label}: {count}\")\n",
    "        \n",
    "        return texts, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dataset Multi-Domain Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDomainSentimentLoader:\n",
    "    \"\"\"\n",
    "    Class for loading and processing the Multi-Domain Sentiment Dataset with enhanced cleaning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_path: str):\n",
    "        \"\"\"\n",
    "        Initializes the loader.\n",
    "        \n",
    "        Args:\n",
    "            root_path: Path to the dataset’s root directory\n",
    "        \"\"\"\n",
    "        self.root_path = Path(root_path)\n",
    "        self.domains = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "        \n",
    "    def _parse_review_line(self, line: str) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Parses a review line from the file.\n",
    "        \n",
    "        Format: word1:freq1 word2:freq2 ... #label#:positive/negative\n",
    "        \n",
    "        Args:\n",
    "            line: Line of the file\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (reconstructed_text, label)\n",
    "        \"\"\"\n",
    "        parts = line.strip().split()\n",
    "        \n",
    "        label = None\n",
    "        words = []\n",
    "        \n",
    "        for part in parts:\n",
    "            if part.startswith('#label#:'):\n",
    "                label = part.split(':')[1]\n",
    "            else:\n",
    "                if ':' in part:\n",
    "                    word, freq = part.rsplit(':', 1)\n",
    "                    try:\n",
    "                        freq = int(freq)\n",
    "                        # Simplification: use each word once\n",
    "                        words.append(word)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        # Reconstruct text\n",
    "        text = ' '.join(words)\n",
    "        \n",
    "        # APPLY CLEANING\n",
    "        cleaned_text = clean_multidomain(text)\n",
    "        \n",
    "        return cleaned_text, label\n",
    "    \n",
    "    def load_domain_data(self, domain: str, sentiment: str, \n",
    "                         max_samples: Optional[int] = None) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Loads data for a specific domain and sentiment.\n",
    "        \n",
    "        Args:\n",
    "            domain: Domain name\n",
    "            sentiment: Sentiment type ('positive' or 'negative')\n",
    "            max_samples: Maximum number of samples to load\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (clean_texts, labels)\n",
    "        \"\"\"\n",
    "        file_path = self.root_path / domain / f\"{sentiment}.review\"\n",
    "        \n",
    "        texts = []\n",
    "        labels = []\n",
    "        \n",
    "        if not file_path.exists():\n",
    "            print(f\"Warning: {file_path} not found\")\n",
    "            return texts, labels\n",
    "        \n",
    "        with open(file_path, 'r', encoding='latin-1') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            if max_samples:\n",
    "                lines = lines[:max_samples]\n",
    "            \n",
    "            for line in lines:\n",
    "                text, label = self._parse_review_line(line)\n",
    "                if text and label and len(text) > 20:  # Filter very short texts\n",
    "                    texts.append(text)\n",
    "                    labels.append(label)\n",
    "        \n",
    "        return texts, labels\n",
    "    \n",
    "    def load_all_data(self, max_samples_per_sentiment: Optional[int] = None) -> Tuple[List[str], List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Loads all data from all domains.\n",
    "        \n",
    "        Args:\n",
    "            max_samples_per_sentiment: Maximum samples per sentiment in each domain\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (clean_texts, labels, domains)\n",
    "        \"\"\"\n",
    "        all_texts = []\n",
    "        all_labels = []\n",
    "        all_domains = []\n",
    "        \n",
    "        print(f\"Loading Multi-Domain Sentiment from: {self.root_path}\")\n",
    "        \n",
    "        for domain in tqdm(self.domains, desc=\"Processing domains\"):\n",
    "            for sentiment in ['positive', 'negative']:\n",
    "                texts, labels = self.load_domain_data(domain, sentiment, max_samples_per_sentiment)\n",
    "                all_texts.extend(texts)\n",
    "                all_labels.extend(labels)\n",
    "                all_domains.extend([domain] * len(texts))\n",
    "                \n",
    "                print(f\"  {domain}/{sentiment}: {len(texts)} samples\")\n",
    "        \n",
    "        print(f\"\\nTotal reviews loaded: {len(all_texts)}\")\n",
    "        print(f\"Sentiment distribution:\")\n",
    "        label_counts = Counter(all_labels)\n",
    "        for label, count in label_counts.items():\n",
    "            print(f\"  {label}: {count}\")\n",
    "        \n",
    "        return all_texts, all_labels, all_domains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classifier Implementations\n",
    "\n",
    "This class uses preprocessed texts for improved classification. Here we implement both a class for GPT-2 and another for Gemma2.\n",
    "\n",
    "Given the extremely poor baseline performance of decoder-only models on the 20Newsgroups dataset—where GPT-2 (124M) and GPT-2-XL (1.5B) achieved accuracies close to random guessing,prompt engineering became essential to guide the model toward the actual classification task. The prompts were redesigned to include three core elements: (1) a minimal task-specific context describing the dataset and the type of text the model would receive, (2) short, carefully selected few-shot examples to anchor the expected output format, and (3) concise phrasing to avoid unnecessary token consumption and to preserve space within the limited context window of decoder-only models. \n",
    "\n",
    "The contextual description helps the model understand that 20Newsgroups posts correspond to forum discussions across specific topical categories, which is not obvious from the raw text alone. The few-shot examples provide explicit demonstrations of how a message maps to a category, reducing ambiguity and forcing the model to mimic the desired output format. Finally, keeping the instructions short ensures that the prompt remains efficient and that the classifier focuses on the essential classification signal rather than being overwhelmed by long instructions or excessive examples. These design decisions directly address the observed failures and aim to improve the model’s ability to distinguish between the highly heterogeneous categories in 20Newsgroups.\n",
    "\n",
    "Below are the previous results obtained without the prompt improvements listed above:\n",
    "\n",
    "| Model           | Preprocessing | Task         | Accuracy | F1 Macro | F1 Micro |\n",
    "| --------------- | ------------- | ------------ | -------- | -------- | -------- |\n",
    "| GPT-2 (124M)    | With cleaning | Sentiment    | 0.501250 | 0.336105 | 0.501250 |\n",
    "| GPT-2-XL (1.5B) | With cleaning | Sentiment    | 0.500000 | 0.333333 | 0.500000 |\n",
    "| GPT-2 (124M)    | With cleaning | 20Newsgroups | 0.056509 | 0.029406 | 0.056509 |\n",
    "| GPT-2-XL (1.5B) | With cleaning | 20Newsgroups | 0.058527 | 0.029013 | 0.058527 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Classifier:\n",
    "    \"\"\"\n",
    "    Classifier based on GPT-2 models using prompting without fine-tuning.\n",
    "    \n",
    "    It now uses PREPROCESSED texts for better performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"gpt2\", device: str = \"cuda\"):\n",
    "        \"\"\"\n",
    "        Initializes the GPT-2 classifier.\n",
    "        \n",
    "        Args:\n",
    "            model_name: GPT-2 model name ('gpt2', 'gpt2-xl')\n",
    "            device: Device to run the model on\n",
    "        \"\"\"\n",
    "        print(f\"\\nLoading model: {model_name}\")\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Configure pad token\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        print(f\"Model successfully loaded on {device}\")\n",
    "        print(f\"Number of parameters: {self.model.num_parameters() / 1e6:.1f}M\")\n",
    "    \n",
    "    def create_prompt(self, text: str, task_type: str, categories: List[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Creates an improved task-specific classification prompt with dataset context,\n",
    "        short examples, and clearer instructions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Truncate long texts\n",
    "        max_text_length = 512\n",
    "        if len(text) > max_text_length:\n",
    "            text = text[:max_text_length] + \"...\"\n",
    "\n",
    "        # -----------------------------\n",
    "        # SENTIMENT ANALYSIS (MDSD)\n",
    "        # -----------------------------\n",
    "        if task_type == 'sentiment':\n",
    "            prompt = (\n",
    "                \"You will classify product reviews from the Multi-Domain Sentiment Dataset.\\n\"\n",
    "                \"Each review expresses either a positive or a negative opinion.\\n\"\n",
    "                \"A positive review indicates satisfaction, good quality, or a good experience.\\n\"\n",
    "                \"A negative review indicates dissatisfaction, poor quality, or a bad experience.\\n\"\n",
    "                \"Respond using only the words 'positive' or 'negative'.\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Review: The product arrived broken and stopped working immediately.\\n\"\n",
    "                \"Sentiment: negative\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Review: Excellent quality, works perfectly and exceeded expectations.\\n\"\n",
    "                \"Sentiment: positive\\n\\n\"\n",
    "                f\"Review: {text}\\n\"\n",
    "                \"Sentiment:\"\n",
    "            )\n",
    "\n",
    "        # -----------------------------\n",
    "        # 20 NEWSGROUPS\n",
    "        # -----------------------------\n",
    "        elif task_type == 'newsgroups':\n",
    "\n",
    "            if not categories or len(categories) == 0:\n",
    "                raise ValueError(\"Categories list is required for newsgroups classification.\")\n",
    "\n",
    "            # Usenet context + instruction to answer with 1 label\n",
    "            prompt = (\n",
    "                \"You will classify a message from the 20 Newsgroups dataset.\\n\"\n",
    "                \"These messages come from online forum discussions (Usenet) across different topics.\\n\"\n",
    "                \"Your task is to identify the single category that best matches the main topic.\\n\"\n",
    "                \"Respond using only one category name from the list.\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Message: I installed the new drivers for my video card and now my system keeps freezing.\\n\"\n",
    "                \"Category: comp.os.ms-windows.misc\\n\\n\"\n",
    "                \"Available categories:\\n\"\n",
    "                f\"{', '.join(categories)}\\n\\n\"\n",
    "                f\"Message: {text}\\n\"\n",
    "                \"Category:\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    \n",
    "    def generate_completion(self, prompt: str, max_new_tokens: int = 20) -> str:\n",
    "        \"\"\"\n",
    "        Generates a completion for the given prompt.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Input prompt\n",
    "            max_new_tokens: Maximum number of tokens to generate\n",
    "            \n",
    "        Returns:\n",
    "            Generated text\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            \n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                do_sample=False,\n",
    "                temperature=1.0\n",
    "            )\n",
    "            \n",
    "            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            completion = generated_text[len(prompt):].strip()\n",
    "            \n",
    "        return completion\n",
    "    \n",
    "    def extract_label_from_completion(self, completion: str, valid_labels: List[str], \n",
    "                                     task_type: str = 'sentiment') -> str:\n",
    "        \"\"\"\n",
    "        Extracts the predicted label from the generated text.\n",
    "        \n",
    "        Args:\n",
    "            completion: Generated model output\n",
    "            valid_labels: List of valid labels\n",
    "            task_type: Task type\n",
    "            \n",
    "        Returns:\n",
    "            Extracted label\n",
    "        \"\"\"\n",
    "        completion_lower = completion.lower()\n",
    "        first_line = completion.split('\\n')[0]\n",
    "        first_words = ' '.join(first_line.split()[:5]).lower()\n",
    "        \n",
    "        if task_type == 'sentiment':\n",
    "            if 'positive' in first_words or 'good' in first_words or 'great' in first_words:\n",
    "                return 'positive'\n",
    "            elif 'negative' in first_words or 'bad' in first_words or 'poor' in first_words:\n",
    "                return 'negative'\n",
    "            else:\n",
    "                first_word = first_line.split()[0].lower() if first_line.split() else ''\n",
    "                if 'pos' in first_word:\n",
    "                    return 'positive'\n",
    "                elif 'neg' in first_word:\n",
    "                    return 'negative'\n",
    "                else:\n",
    "                    return 'positive'\n",
    "        \n",
    "        else:  # newsgroups\n",
    "            for label in valid_labels:\n",
    "                label_parts = label.split('.')\n",
    "                for part in label_parts:\n",
    "                    if part.lower() in first_words:\n",
    "                        return label\n",
    "            \n",
    "            best_match = None\n",
    "            max_overlap = 0\n",
    "            \n",
    "            for label in valid_labels:\n",
    "                label_words = set(label.lower().replace('.', ' ').split())\n",
    "                completion_words = set(first_words.split())\n",
    "                overlap = len(label_words & completion_words)\n",
    "                \n",
    "                if overlap > max_overlap:\n",
    "                    max_overlap = overlap\n",
    "                    best_match = label\n",
    "            \n",
    "            return best_match if best_match else valid_labels[0]\n",
    "    \n",
    "    def predict(self, texts: List[str], task_type: str, \n",
    "                valid_labels: List[str], batch_size: int = 1) -> List[str]:\n",
    "        \"\"\"\n",
    "        Predicts labels for a list of clean texts.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of CLEAN texts to classify\n",
    "            task_type: Type of task\n",
    "            valid_labels: List of valid labels\n",
    "            batch_size: Batch size\n",
    "            \n",
    "        Returns:\n",
    "            List of predictions\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        print(f\"\\nRunning predictions with {self.model_name}...\")\n",
    "        \n",
    "        for text in tqdm(texts, desc=\"Classifying\"):\n",
    "            prompt = self.create_prompt(text, task_type, valid_labels)\n",
    "            completion = self.generate_completion(prompt)\n",
    "            label = self.extract_label_from_completion(completion, valid_labels, task_type)\n",
    "            predictions.append(label)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemma2Classifier:\n",
    "    \"\"\"\n",
    "    Classifier based on prompting without fine-tuning.\n",
    "    Compatible with Gemma 2 (2B/2B-it) loaded via Transformers.\n",
    "    Preserves the same prompt style and label extraction logic\n",
    "    as the original GPT-2 snippet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = None,\n",
    "        device: str = None,\n",
    "        tokenizer: AutoTokenizer = None,\n",
    "        model: AutoModelForCausalLM = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: HF model ID (e.g. \"google/gemma-2-2b\" or \"google/gemma-2-2b-it\").\n",
    "            device: \"cuda\" or \"cpu\" (if None, auto-detect).\n",
    "            tokenizer: Optional preloaded tokenizer.\n",
    "            model: Optional preloaded model.\n",
    "        \"\"\"\n",
    "        # Device selection\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Reuse provided or global objects\n",
    "        if tokenizer is not None and model is not None:\n",
    "            self.tokenizer = tokenizer\n",
    "            self.model = model\n",
    "            self.model_name = getattr(model.config, \"name_or_path\", \"gemma2\")\n",
    "        else:\n",
    "            if \"tokenizer\" in globals() and \"model\" in globals():\n",
    "                self.tokenizer = globals()[\"tokenizer\"]\n",
    "                self.model = globals()[\"model\"]\n",
    "                self.model_name = getattr(self.model.config, \"name_or_path\", \"gemma2\")\n",
    "            else:\n",
    "                if model_name is None:\n",
    "                    model_name = \"google/gemma-2-2b\"\n",
    "                print(f\"\\nLoading model: {model_name}\")\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    model_name,\n",
    "                    trust_remote_code=True\n",
    "                )\n",
    "\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Ensure pad token\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        print(f\"Model '{self.model_name}' ready on {self.device}\")\n",
    "        try:\n",
    "            print(f\"Number of parameters: {self.model.num_parameters() / 1e6:.1f}M\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    def create_prompt(self, text: str, task_type: str, categories: List[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Creates an improved task-specific classification prompt with dataset context,\n",
    "        short examples, and clearer instructions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Truncate long texts\n",
    "        max_text_length = 350\n",
    "        if len(text) > max_text_length:\n",
    "            text = text[:max_text_length] + \"...\"\n",
    "\n",
    "        # -----------------------------\n",
    "        # SENTIMENT ANALYSIS (MDSD)\n",
    "        # -----------------------------\n",
    "        if task_type == 'sentiment':\n",
    "            prompt = (\n",
    "                \"You will classify product reviews from the Multi-Domain Sentiment Dataset.\\n\"\n",
    "                \"Each review expresses either a positive or a negative opinion.\\n\"\n",
    "                \"A positive review indicates satisfaction, good quality, or a good experience.\\n\"\n",
    "                \"A negative review indicates dissatisfaction, poor quality, or a bad experience.\\n\"\n",
    "                \"Respond using only the words 'positive' or 'negative'.\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Review: The product arrived broken and stopped working immediately.\\n\"\n",
    "                \"Sentiment: negative\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Review: Excellent quality, works perfectly and exceeded expectations.\\n\"\n",
    "                \"Sentiment: positive\\n\\n\"\n",
    "                f\"Review: {text}\\n\"\n",
    "                \"Sentiment:\"\n",
    "            )\n",
    "\n",
    "        # -----------------------------\n",
    "        # 20 NEWSGROUPS\n",
    "        # -----------------------------\n",
    "        elif task_type == 'newsgroups':\n",
    "\n",
    "            if not categories or len(categories) == 0:\n",
    "                raise ValueError(\"Categories list is required for newsgroups classification.\")\n",
    "\n",
    "            # Usenet context + instruction to answer with 1 label\n",
    "            prompt = (\n",
    "                \"You will classify a message from the 20 Newsgroups dataset.\\n\"\n",
    "                \"These messages come from online forum discussions (Usenet) across different topics.\\n\"\n",
    "                \"Your task is to identify the single category that best matches the main topic.\\n\"\n",
    "                \"Respond using only one category name from the list.\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Message: I installed the new drivers for my video card and now my system keeps freezing.\\n\"\n",
    "                \"Category: comp.os.ms-windows.misc\\n\\n\"\n",
    "                \"Available categories:\\n\"\n",
    "                f\"{', '.join(categories)}\\n\\n\"\n",
    "                f\"Message: {text}\\n\"\n",
    "                \"Category:\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "\n",
    "        return prompt\n",
    "\n",
    "\n",
    "    def generate_completion(self, prompt: str, max_new_tokens: int = 20) -> str:\n",
    "        \"\"\"\n",
    "        Generates continuation for the given prompt (greedy decoding,\n",
    "        same behavior as the original implementation).\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                do_sample=False,\n",
    "                temperature=1.0\n",
    "            )\n",
    "\n",
    "            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        if generated_text.startswith(prompt):\n",
    "            completion = generated_text[len(prompt):].strip()\n",
    "        else:\n",
    "            anchor = \"Category:\" if \"Category:\" in prompt else \"Sentiment:\"\n",
    "            completion = generated_text.split(anchor)[-1].strip()\n",
    "\n",
    "        return completion\n",
    "\n",
    "    def extract_label_from_completion(\n",
    "        self,\n",
    "        completion: str,\n",
    "        valid_labels: List[str],\n",
    "        task_type: str = \"sentiment\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Extracts the label from the first line/words of the output.\n",
    "        Same logic as the original snippet.\n",
    "        \"\"\"\n",
    "        first_line = completion.split(\"\\n\")[0]\n",
    "        first_words = \" \".join(first_line.split()[:5]).lower()\n",
    "\n",
    "        if task_type == \"sentiment\":\n",
    "            if any(x in first_words for x in [\"positive\", \"good\", \"great\"]):\n",
    "                return \"positive\"\n",
    "            if any(x in first_words for x in [\"negative\", \"bad\", \"poor\"]):\n",
    "                return \"negative\"\n",
    "            first_word = first_line.split()[0].lower() if first_line.split() else \"\"\n",
    "            if \"pos\" in first_word:\n",
    "                return \"positive\"\n",
    "            if \"neg\" in first_word:\n",
    "                return \"negative\"\n",
    "            return \"positive\"\n",
    "\n",
    "        else:  # newsgroups\n",
    "            for label in valid_labels:\n",
    "                for part in label.split(\".\"):\n",
    "                    if part.lower() in first_words:\n",
    "                        return label\n",
    "\n",
    "            best_match, max_overlap = None, 0\n",
    "            completion_words = set(first_words.split())\n",
    "            for label in valid_labels:\n",
    "                label_words = set(label.lower().replace(\".\", \" \").split())\n",
    "                overlap = len(label_words & completion_words)\n",
    "                if overlap > max_overlap:\n",
    "                    max_overlap = overlap\n",
    "                    best_match = label\n",
    "\n",
    "            return best_match if best_match else valid_labels[0]\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        task_type: str,\n",
    "        valid_labels: List[str],\n",
    "        batch_size: int = 1\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Classifies a list of clean texts using prompting.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        print(f\"\\nRunning predictions with {getattr(self.model.config, 'name_or_path', 'gemma2')}...\")\n",
    "\n",
    "        for text in tqdm(texts, desc=\"Classifying\"):\n",
    "            prompt = self.create_prompt(text, task_type, valid_labels)\n",
    "            completion = self.generate_completion(prompt)\n",
    "            label = self.extract_label_from_completion(completion, valid_labels, task_type)\n",
    "            predictions.append(label)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(y_true: List[str], y_pred: List[str], \n",
    "                       label_names: List[str] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluates classifier performance.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels\n",
    "        label_names: Label names\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with metrics\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    report = classification_report(y_true, y_pred, target_names=label_names, zero_division=0)\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_micro': recall_micro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'report': report\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_results(results: Dict, model_name: str, task_name: str):\n",
    "    \"\"\"\n",
    "    Prints evaluation results.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Results: {model_name} - {task_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nAccuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"\\nMacro Metrics:\")\n",
    "    print(f\"  Precision: {results['precision_macro']:.4f}\")\n",
    "    print(f\"  Recall:    {results['recall_macro']:.4f}\")\n",
    "    print(f\"  F1-Score:  {results['f1_macro']:.4f}\")\n",
    "    print(f\"\\nMicro Metrics:\")\n",
    "    print(f\"  Precision: {results['precision_micro']:.4f}\")\n",
    "    print(f\"  Recall:    {results['recall_micro']:.4f}\")\n",
    "    print(f\"  F1-Score:  {results['f1_micro']:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(results['report'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiments\n",
    "\n",
    "The experiments consisted of evaluating decoder-only language models on two text classification tasks using cleaned versions of the Multi-Domain Sentiment dataset and the 20Newsgroups corpus. For each dataset, three models were tested: GPT-2 (124M), GPT-2-XL (1.5B), and Gemma-2, all used without fine-tuning and relying solely on prompting. The procedure involved loading and preprocessing the datasets, generating predictions through task-specific prompts, and computing standard evaluation metrics including accuracy and F1 scores.\n",
    "\n",
    "### 5.1 Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACIÓN\n",
    "NEWSGROUPS_PATH = \"20news-18828\"  \n",
    "SENTIMENT_PATH = \"processed_acl\"  \n",
    "\n",
    "# Parámetros para limitar el tamaño (ajustar según recursos)\n",
    "MAX_SAMPLES_NEWSGROUPS = 50  # Por categoría\n",
    "MAX_SAMPLES_SENTIMENT = 100  # Por sentimiento/dominio\n",
    "\n",
    "# Para experimento completo:\n",
    "# MAX_SAMPLES_NEWSGROUPS = None\n",
    "# MAX_SAMPLES_SENTIMENT = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Load Data (with automatic cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CARGANDO Y LIMPIANDO MULTI-DOMAIN SENTIMENT\n",
      "================================================================================\n",
      "Cargando Multi-Domain Sentiment desde: processed_acl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando dominios: 100%|██████████| 4/4 [00:00<00:00, 25.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  books/positive: 100 muestras\n",
      "  books/negative: 100 muestras\n",
      "  dvd/positive: 100 muestras\n",
      "  dvd/negative: 100 muestras\n",
      "  electronics/positive: 100 muestras\n",
      "  electronics/negative: 100 muestras\n",
      "  kitchen/positive: 100 muestras\n",
      "  kitchen/negative: 100 muestras\n",
      "\n",
      "Total de reviews cargadas: 800\n",
      "Distribución de sentimientos:\n",
      "  positive: 400\n",
      "  negative: 400\n",
      "\n",
      " Dataset limpio:\n",
      "Total: 800 muestras\n",
      "\n",
      "Ejemplo de texto limpio:\n",
      "holes must top secret he center other civilans the pacific the navy a lot surface must this book man named feet would strongly put down norman johnson lawes a top the support ten on random typhoon a p...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar Multi-Domain Sentiment con limpieza\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CARGANDO Y LIMPIANDO MULTI-DOMAIN SENTIMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sentiment_loader = MultiDomainSentimentLoader(SENTIMENT_PATH)\n",
    "texts_sentiment, labels_sentiment, domains_sentiment = sentiment_loader.load_all_data(\n",
    "    max_samples_per_sentiment=MAX_SAMPLES_SENTIMENT\n",
    ")\n",
    "\n",
    "print(f\"\\n Dataset limpio:\")\n",
    "print(f\"Total: {len(texts_sentiment)} muestras\")\n",
    "print(f\"\\nEjemplo de texto limpio:\")\n",
    "print(f\"{texts_sentiment[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CARGANDO Y LIMPIANDO 20NEWSGROUPS\n",
      "================================================================================\n",
      "Cargando 20Newsgroups desde: 20news-18828\n",
      "Categorías encontradas: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando categorías: 100%|██████████| 20/20 [00:00<00:00, 72.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de documentos cargados: 991\n",
      "Distribución por categoría:\n",
      "  alt.atheism: 50\n",
      "  comp.graphics: 50\n",
      "  comp.os.ms-windows.misc: 49\n",
      "  comp.sys.ibm.pc.hardware: 50\n",
      "  comp.sys.mac.hardware: 48\n",
      "  comp.windows.x: 49\n",
      "  misc.forsale: 50\n",
      "  rec.autos: 50\n",
      "  rec.motorcycles: 48\n",
      "  rec.sport.baseball: 50\n",
      "  rec.sport.hockey: 50\n",
      "  sci.crypt: 50\n",
      "  sci.electronics: 49\n",
      "  sci.med: 49\n",
      "  sci.space: 50\n",
      "  soc.religion.christian: 50\n",
      "  talk.politics.guns: 50\n",
      "  talk.politics.mideast: 50\n",
      "  talk.politics.misc: 49\n",
      "  talk.religion.misc: 50\n",
      "\n",
      " Dataset limpio:\n",
      "Total: 991 documentos\n",
      "Categorías: 20\n",
      "\n",
      "Ejemplo de texto limpio:\n",
      "One thing I think is interesting about alt.athiesm is the fact that without bible-thumpers and their ilk this would be a much duller newsgroup. It almost needs the deluded masses to write silly things...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load 20Newsgroups with cleaning\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING AND CLEANING 20NEWSGROUPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "newsgroups_loader = NewsGroupsLoader(NEWSGROUPS_PATH)\n",
    "texts_newsgroups, labels_newsgroups = newsgroups_loader.load_data(\n",
    "    max_samples_per_category=MAX_SAMPLES_NEWSGROUPS\n",
    ")\n",
    "\n",
    "unique_categories = sorted(list(set(labels_newsgroups)))\n",
    "\n",
    "print(f\"\\n Clean dataset:\")\n",
    "print(f\"Total: {len(texts_newsgroups)} documents\")\n",
    "print(f\"Categories: {len(unique_categories)}\")\n",
    "print(f\"\\nExample of cleaned text:\")\n",
    "print(f\"{texts_newsgroups[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Experimento 1: Sentiment Analysis con GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando modelo: gpt2\n",
      "Modelo cargado exitosamente en cuda\n",
      "Número de parámetros: 124.4M\n",
      "\n",
      "Realizando predicciones con gpt2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clasificando: 100%|██████████| 800/800 [02:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Resultados: GPT-2 (con preprocesamiento) - Sentiment Analysis\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.5012\n",
      "\n",
      "Métricas Macro:\n",
      "  Precision: 0.7503\n",
      "  Recall:    0.5012\n",
      "  F1-Score:  0.3361\n",
      "\n",
      "Métricas Micro:\n",
      "  Precision: 0.5012\n",
      "  Recall:    0.5012\n",
      "  F1-Score:  0.5012\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.00      0.00       400\n",
      "    positive       0.50      1.00      0.67       400\n",
      "\n",
      "    accuracy                           0.50       800\n",
      "   macro avg       0.75      0.50      0.34       800\n",
      "weighted avg       0.75      0.50      0.34       800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPT-2\n",
    "gpt2_classifier = GPT2Classifier(model_name=\"gpt2\", device=device)\n",
    "\n",
    "# Predictions\n",
    "predictions_gpt2_sentiment = gpt2_classifier.predict(\n",
    "    texts=texts_sentiment,\n",
    "    task_type='sentiment',\n",
    "    valid_labels=['positive', 'negative']\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "results_gpt2_sentiment = evaluate_classifier(\n",
    "    y_true=labels_sentiment,\n",
    "    y_pred=predictions_gpt2_sentiment,\n",
    "    label_names=['negative', 'positive']\n",
    ")\n",
    "\n",
    "print_results(results_gpt2_sentiment, \"GPT-2 (with preprocessing)\", \"Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Experiment 2: Sentiment Analysis with GPT-2-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando modelo: gpt2-xl\n",
      "Modelo cargado exitosamente en cuda\n",
      "Número de parámetros: 1557.6M\n",
      "\n",
      "Realizando predicciones con gpt2-xl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clasificando: 100%|██████████| 800/800 [06:52<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Resultados: GPT-2-XL (con preprocesamiento) - Sentiment Analysis\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.5000\n",
      "\n",
      "Métricas Macro:\n",
      "  Precision: 0.2500\n",
      "  Recall:    0.5000\n",
      "  F1-Score:  0.3333\n",
      "\n",
      "Métricas Micro:\n",
      "  Precision: 0.5000\n",
      "  Recall:    0.5000\n",
      "  F1-Score:  0.5000\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       400\n",
      "    positive       0.50      1.00      0.67       400\n",
      "\n",
      "    accuracy                           0.50       800\n",
      "   macro avg       0.25      0.50      0.33       800\n",
      "weighted avg       0.25      0.50      0.33       800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPT-2-XL\n",
    "gpt2xl_classifier = GPT2Classifier(model_name=\"gpt2-xl\", device=device)\n",
    "\n",
    "# Predictions\n",
    "predictions_gpt2xl_sentiment = gpt2xl_classifier.predict(\n",
    "    texts=texts_sentiment,\n",
    "    task_type='sentiment',\n",
    "    valid_labels=['positive', 'negative']\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "results_gpt2xl_sentiment = evaluate_classifier(\n",
    "    y_true=labels_sentiment,\n",
    "    y_pred=predictions_gpt2xl_sentiment,\n",
    "    label_names=['negative', 'positive']\n",
    ")\n",
    "\n",
    "print_results(results_gpt2xl_sentiment, \"GPT-2-XL (with preprocessing)\", \"Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Experiment 4: Sentiment Analysis with Gemma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'google/gemma-2-2b' listo en cuda\n",
      "Número de parámetros: 2614.3M\n",
      "\n",
      "Realizando predicciones con google/gemma-2-2b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clasificando: 100%|██████████| 800/800 [11:55<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Resultados: GPT-2 (con preprocesamiento) - Sentiment Analysis\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.5025\n",
      "\n",
      "Métricas Macro:\n",
      "  Precision: 0.7506\n",
      "  Recall:    0.5025\n",
      "  F1-Score:  0.3389\n",
      "\n",
      "Métricas Micro:\n",
      "  Precision: 0.5025\n",
      "  Recall:    0.5025\n",
      "  F1-Score:  0.5025\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.01      0.01       400\n",
      "    positive       0.50      1.00      0.67       400\n",
      "\n",
      "    accuracy                           0.50       800\n",
      "   macro avg       0.75      0.50      0.34       800\n",
      "weighted avg       0.75      0.50      0.34       800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemma2\n",
    "gemma2_classifier = Gemma2Classifier(device=\"cuda\")\n",
    "\n",
    "# Predictions\n",
    "predictions_gemma2_sentiment = gemma2_classifier.predict(\n",
    "    texts=texts_sentiment,\n",
    "    task_type='sentiment',\n",
    "    valid_labels=['positive', 'negative']\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "results_gemma2_sentiment = evaluate_classifier(\n",
    "    y_true=labels_sentiment,\n",
    "    y_pred=predictions_gemma2_sentiment,\n",
    "    label_names=['negative', 'positive']\n",
    ")\n",
    "\n",
    "print_results(results_gemma2_sentiment, \"Gemma2 (with preprocessing)\", \"Sentiment Analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Experiment 4: 20Newsgroups with GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando predicciones con gpt2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clasificando: 100%|██████████| 991/991 [02:33<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Resultados: GPT-2 (con preprocesamiento) - 20Newsgroups\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.0565\n",
      "\n",
      "Métricas Macro:\n",
      "  Precision: 0.0693\n",
      "  Recall:    0.0562\n",
      "  F1-Score:  0.0294\n",
      "\n",
      "Métricas Micro:\n",
      "  Precision: 0.0565\n",
      "  Recall:    0.0565\n",
      "  F1-Score:  0.0565\n",
      "\n",
      "Reporte de Clasificación:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.05      0.36      0.09        50\n",
      "           comp.graphics       0.09      0.08      0.09        50\n",
      " comp.os.ms-windows.misc       0.09      0.06      0.07        49\n",
      "comp.sys.ibm.pc.hardware       0.33      0.02      0.04        50\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00        48\n",
      "          comp.windows.x       0.28      0.14      0.19        49\n",
      "            misc.forsale       0.00      0.00      0.00        50\n",
      "               rec.autos       0.04      0.44      0.08        50\n",
      "         rec.motorcycles       0.00      0.00      0.00        48\n",
      "      rec.sport.baseball       0.00      0.00      0.00        50\n",
      "        rec.sport.hockey       0.00      0.00      0.00        50\n",
      "               sci.crypt       0.50      0.02      0.04        50\n",
      "         sci.electronics       0.00      0.00      0.00        49\n",
      "                 sci.med       0.00      0.00      0.00        49\n",
      "               sci.space       0.00      0.00      0.00        50\n",
      "  soc.religion.christian       0.00      0.00      0.00        50\n",
      "      talk.politics.guns       0.00      0.00      0.00        50\n",
      "   talk.politics.mideast       0.00      0.00      0.00        50\n",
      "      talk.politics.misc       0.00      0.00      0.00        49\n",
      "      talk.religion.misc       0.00      0.00      0.00        50\n",
      "\n",
      "                accuracy                           0.06       991\n",
      "               macro avg       0.07      0.06      0.03       991\n",
      "            weighted avg       0.07      0.06      0.03       991\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicciones\n",
    "predictions_gpt2_newsgroups = gpt2_classifier.predict(\n",
    "    texts=texts_newsgroups,\n",
    "    task_type='newsgroups',\n",
    "    valid_labels=unique_categories\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "results_gpt2_newsgroups = evaluate_classifier(\n",
    "    y_true=labels_newsgroups,\n",
    "    y_pred=predictions_gpt2_newsgroups,\n",
    "    label_names=unique_categories\n",
    ")\n",
    "\n",
    "print_results(results_gpt2_newsgroups, \"GPT-2 (con preprocesamiento)\", \"20Newsgroups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Experiment 5: 20Newsgroups with GPT-2-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando predicciones con gpt2-xl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clasificando: 100%|██████████| 991/991 [08:52<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Resultados: GPT-2-XL (con preprocesamiento) - 20Newsgroups\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.0585\n",
      "\n",
      "Métricas Macro:\n",
      "  Precision: 0.1389\n",
      "  Recall:    0.0581\n",
      "  F1-Score:  0.0290\n",
      "\n",
      "Métricas Micro:\n",
      "  Precision: 0.0585\n",
      "  Recall:    0.0585\n",
      "  F1-Score:  0.0585\n",
      "\n",
      "Reporte de Clasificación:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.05      0.60      0.09        50\n",
      "           comp.graphics       0.15      0.30      0.20        50\n",
      " comp.os.ms-windows.misc       0.22      0.04      0.07        49\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00        50\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00        48\n",
      "          comp.windows.x       0.33      0.06      0.10        49\n",
      "            misc.forsale       0.00      0.00      0.00        50\n",
      "               rec.autos       0.02      0.12      0.04        50\n",
      "         rec.motorcycles       0.00      0.00      0.00        48\n",
      "      rec.sport.baseball       1.00      0.02      0.04        50\n",
      "        rec.sport.hockey       0.00      0.00      0.00        50\n",
      "               sci.crypt       1.00      0.02      0.04        50\n",
      "         sci.electronics       0.00      0.00      0.00        49\n",
      "                 sci.med       0.00      0.00      0.00        49\n",
      "               sci.space       0.00      0.00      0.00        50\n",
      "  soc.religion.christian       0.00      0.00      0.00        50\n",
      "      talk.politics.guns       0.00      0.00      0.00        50\n",
      "   talk.politics.mideast       0.00      0.00      0.00        50\n",
      "      talk.politics.misc       0.00      0.00      0.00        49\n",
      "      talk.religion.misc       0.00      0.00      0.00        50\n",
      "\n",
      "                accuracy                           0.06       991\n",
      "               macro avg       0.14      0.06      0.03       991\n",
      "            weighted avg       0.14      0.06      0.03       991\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicciones\n",
    "predictions_gpt2xl_newsgroups = gpt2xl_classifier.predict(\n",
    "    texts=texts_newsgroups,\n",
    "    task_type='newsgroups',\n",
    "    valid_labels=unique_categories\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "results_gpt2xl_newsgroups = evaluate_classifier(\n",
    "    y_true=labels_newsgroups,\n",
    "    y_pred=predictions_gpt2xl_newsgroups,\n",
    "    label_names=unique_categories\n",
    ")\n",
    "\n",
    "print_results(results_gpt2xl_newsgroups, \"GPT-2-XL (with preprocessing)\", \"20Newsgroups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Experiment 6: 20Newsgroups with Gemma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando predicciones con google/gemma-2-2b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clasificando: 100%|██████████| 991/991 [14:56<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Resultados: GPT-2 (con preprocesamiento) - 20Newsgroups\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.0505\n",
      "\n",
      "Métricas Macro:\n",
      "  Precision: 0.0025\n",
      "  Recall:    0.0500\n",
      "  F1-Score:  0.0048\n",
      "\n",
      "Métricas Micro:\n",
      "  Precision: 0.0505\n",
      "  Recall:    0.0505\n",
      "  F1-Score:  0.0505\n",
      "\n",
      "Reporte de Clasificación:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.05      1.00      0.10        50\n",
      "           comp.graphics       0.00      0.00      0.00        50\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00        49\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00        50\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00        48\n",
      "          comp.windows.x       0.00      0.00      0.00        49\n",
      "            misc.forsale       0.00      0.00      0.00        50\n",
      "               rec.autos       0.00      0.00      0.00        50\n",
      "         rec.motorcycles       0.00      0.00      0.00        48\n",
      "      rec.sport.baseball       0.00      0.00      0.00        50\n",
      "        rec.sport.hockey       0.00      0.00      0.00        50\n",
      "               sci.crypt       0.00      0.00      0.00        50\n",
      "         sci.electronics       0.00      0.00      0.00        49\n",
      "                 sci.med       0.00      0.00      0.00        49\n",
      "               sci.space       0.00      0.00      0.00        50\n",
      "  soc.religion.christian       0.00      0.00      0.00        50\n",
      "      talk.politics.guns       0.00      0.00      0.00        50\n",
      "   talk.politics.mideast       0.00      0.00      0.00        50\n",
      "      talk.politics.misc       0.00      0.00      0.00        49\n",
      "      talk.religion.misc       0.00      0.00      0.00        50\n",
      "\n",
      "                accuracy                           0.05       991\n",
      "               macro avg       0.00      0.05      0.00       991\n",
      "            weighted avg       0.00      0.05      0.00       991\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicciones\n",
    "predictions_gemma2_newsgroups = gemma2_classifier.predict(\n",
    "    texts=texts_newsgroups,\n",
    "    task_type='newsgroups',\n",
    "    valid_labels=unique_categories\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "results_gemma2_newsgroups = evaluate_classifier(\n",
    "    y_true=labels_newsgroups,\n",
    "    y_pred=predictions_gemma2_newsgroups,\n",
    "    label_names=unique_categories\n",
    ")\n",
    "\n",
    "print_results(results_gemma2_newsgroups, \"Gemma2 (with preprocessing)\", \"20Newsgroups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results comparison and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARACIÓN DE RESULTADOS (CON PREPROCESAMIENTO)\n",
      "================================================================================\n",
      "         Modelo Preprocesamiento        Tarea  Accuracy  F1 Macro  F1 Micro\n",
      "   GPT-2 (124M)     Con limpieza    Sentiment  0.501250  0.336105  0.501250\n",
      "GPT-2-XL (1.5B)     Con limpieza    Sentiment  0.500000  0.333333  0.500000\n",
      "   GPT-2 (124M)     Con limpieza 20Newsgroups  0.056509  0.029406  0.056509\n",
      "GPT-2-XL (1.5B)     Con limpieza 20Newsgroups  0.058527  0.029013  0.058527\n",
      "\n",
      " Resultados guardados en: results_decoders_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table\n",
    "comparison_data = [\n",
    "    {\n",
    "        'Model': 'GPT-2 (124M)',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': 'Sentiment',\n",
    "        'Accuracy': results_gpt2_sentiment['accuracy'],\n",
    "        'F1 Macro': results_gpt2_sentiment['f1_macro'],\n",
    "        'F1 Micro': results_gpt2_sentiment['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'GPT-2-XL (1.5B)',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': 'Sentiment',\n",
    "        'Accuracy': results_gpt2xl_sentiment['accuracy'],\n",
    "        'F1 Macro': results_gpt2xl_sentiment['f1_macro'],\n",
    "        'F1 Micro': results_gpt2xl_sentiment['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Gemma2',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': 'Sentiment',\n",
    "        'Accuracy': results_gemma2_sentiment['accuracy'],\n",
    "        'F1 Macro': results_gemma2_sentiment['f1_macro'],\n",
    "        'F1 Micro': results_gemma2_sentiment['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'GPT-2 (124M)',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': '20Newsgroups',\n",
    "        'Accuracy': results_gpt2_newsgroups['accuracy'],\n",
    "        'F1 Macro': results_gpt2_newsgroups['f1_macro'],\n",
    "        'F1 Micro': results_gpt2_newsgroups['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'GPT-2-XL (1.5B)',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': '20Newsgroups',\n",
    "        'Accuracy': results_gpt2xl_newsgroups['accuracy'],\n",
    "        'F1 Macro': results_gpt2xl_newsgroups['f1_macro'],\n",
    "        'F1 Micro': results_gpt2xl_newsgroups['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Gemma2',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': '20Newsgroups',\n",
    "        'Accuracy': results_gemma2_newsgroups['accuracy'],\n",
    "        'F1 Macro': results_gemma2_newsgroups['f1_macro'],\n",
    "        'F1 Micro': results_gemma2_newsgroups['f1_micro']\n",
    "    }\n",
    "]\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS COMPARISON (WITH PREPROCESSING)\")\n",
    "print(\"=\"*80)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Save\n",
    "df_comparison.to_csv('outputs/results_decoders_preprocessed.csv', index=False)\n",
    "print(\"\\nResults saved to: results_decoders_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Gráfico guardado en: comparison_preprocessed.png\n"
     ]
    }
   ],
   "source": [
    "# Comparative plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Sentiment Analysis\n",
    "sentiment_data = df_comparison[df_comparison['Task'] == 'Sentiment']\n",
    "x_pos = np.arange(len(sentiment_data))\n",
    "axes[0].bar(x_pos - 0.2, sentiment_data['Accuracy'], 0.4, label='Accuracy', alpha=0.8)\n",
    "axes[0].bar(x_pos + 0.2, sentiment_data['F1 Macro'], 0.4, label='F1 Macro', alpha=0.8)\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Sentiment Analysis (with preprocessing)')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(sentiment_data['Model'], rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# 20Newsgroups\n",
    "newsgroups_data = df_comparison[df_comparison['Task'] == '20Newsgroups']\n",
    "x_pos = np.arange(len(newsgroups_data))\n",
    "axes[1].bar(x_pos - 0.2, newsgroups_data['Accuracy'], 0.4, label='Accuracy', alpha=0.8)\n",
    "axes[1].bar(x_pos + 0.2, newsgroups_data['F1 Macro'], 0.4, label='F1 Macro', alpha=0.8)\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('20Newsgroups (with preprocessing)')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(newsgroups_data['Model'], rotation=45, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/comparison_preprocessed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved as: comparison_preprocessed.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-1 (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
