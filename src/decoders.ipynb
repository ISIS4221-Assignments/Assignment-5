{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admonsis/.venv-1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel, \n",
    "    GPT2Tokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración de dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Model definitions and loading:\n",
    "\n",
    "The decoder models to be used are:\n",
    "\n",
    "- GPT-2 (124M parameters)\n",
    "- GPT-2-XL (1.5B parameters)\n",
    "- Gemma2 (2B parameters)\n",
    "\n",
    "This section loads the models and defines the generation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /home/admonsis/.venv-1/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: filelock in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: networkx in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: fsspec in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.9.86)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --index-url https://download.pytorch.org/whl/cu121 torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers scikit-learn pandas numpy tqdm matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/admonsis/.venv-1/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/admonsis/.venv-1/lib/python3.10/site-packages (0.48.2)\n",
      "Requirement already satisfied: torch in /home/admonsis/.venv-1/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors>=0.4.3 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: pyyaml in /home/admonsis/.venv-1/lib/python3.10/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/admonsis/.venv-1/lib/python3.10/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: psutil in /home/admonsis/.venv-1/lib/python3.10/site-packages (from accelerate) (7.1.3)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.8.4.1\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/594.3 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m386.3/594.3 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# === Gemma 2 (≤7B) setup via Hugging Face Transformers (PyTorch) ===\n",
    "# Requisitos:\n",
    "!pip install -U accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id = os.environ.get(\"GEMMA2_MODEL_ID\", \"google/gemma-2-2b\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "def gemma2_generate(prompt, max_new_tokens=128, temperature=0.7, top_p=0.95):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Functions (from the encoder notebook)\n",
    "\n",
    "These functions clean the texts by removing:\n",
    "\n",
    "* **20Newsgroups**: Email headers, email addresses, URLs, signatures, quoted lines\n",
    "* **Multi-Domain Sentiment**: Underscores, special tokens such as `<num>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_20_news(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans a 20 Newsgroups document by removing email metadata and artifacts.\n",
    "    \n",
    "    Steps:\n",
    "    1. Removes common email headers (From, Subject, Organization, etc.)\n",
    "    2. Deletes email addresses and URLs using regex\n",
    "    3. Removes signature lines and separators ('--', '__')\n",
    "    4. Removes quoted lines starting with '>' or ':'\n",
    "    5. Collapses multiple newlines and spaces for consistent formatting\n",
    "    \n",
    "    Args:\n",
    "        text: Raw email or newsgroup message text\n",
    "        \n",
    "    Returns:\n",
    "        Clean text containing only meaningful content\n",
    "    \"\"\"\n",
    "    # Remove common email headers\n",
    "    text = re.sub(r'^(From|Subject|Lines|Organization|Reply-To|NNTP-Posting-Host|Keywords|Summary):.*$', \n",
    "                  '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove email addresses and URLs\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove signature lines or separators\n",
    "    text = re.sub(r'--+\\s*$', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'_+', '', text)\n",
    "    \n",
    "    # Remove quoted lines (starting with > or :)\n",
    "    text = re.sub(r'(^>.*$|^:.*$)', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Collapse multiple newlines and spaces\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def clean_multidomain(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Simplifies review text from the Multi-Domain Sentiment dataset.\n",
    "    \n",
    "    Steps:\n",
    "    1. Replaces underscores with spaces to normalize tokens\n",
    "    2. Removes placeholder tokens like '<num>'\n",
    "    3. Eliminates redundant spaces\n",
    "    \n",
    "    Args:\n",
    "        text: Raw dataset text\n",
    "        \n",
    "    Returns:\n",
    "        Clean version of the text\n",
    "    \"\"\"\n",
    "    # Replace underscores with spaces\n",
    "    text = text.replace(\"_\", \" \")\n",
    "    \n",
    "    # Remove special tokens like <num>\n",
    "    text = re.sub(r\"<num>\", \"\", text)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Datasets with Preprocessing\n",
    "\n",
    "### 2.1 20Newsgroups Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsGroupsLoader:\n",
    "    \"\"\"\n",
    "    Class for loading and processing the 20Newsgroups dataset with enhanced cleaning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_path: str):\n",
    "        \"\"\"\n",
    "        Initializes the loader.\n",
    "        \n",
    "        Args:\n",
    "            root_path: Path to the dataset’s root directory\n",
    "        \"\"\"\n",
    "        self.root_path = Path(root_path)\n",
    "        self.categories = self._get_categories()\n",
    "        \n",
    "    def _get_categories(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the list of dataset categories.\n",
    "        \n",
    "        Returns:\n",
    "            Sorted list of category names\n",
    "        \"\"\"\n",
    "        categories = [d.name for d in self.root_path.iterdir() if d.is_dir()]\n",
    "        return sorted(categories)\n",
    "    \n",
    "    def load_data(self, max_samples_per_category: Optional[int] = None) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Loads dataset samples with automatic cleaning.\n",
    "        \n",
    "        Args:\n",
    "            max_samples_per_category: Maximum number of samples per category\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (clean_texts, labels)\n",
    "        \"\"\"\n",
    "        texts = []\n",
    "        labels = []\n",
    "        \n",
    "        print(f\"Loading 20Newsgroups from: {self.root_path}\")\n",
    "        print(f\"Categories found: {len(self.categories)}\")\n",
    "        \n",
    "        for category in tqdm(self.categories, desc=\"Processing categories\"):\n",
    "            category_path = self.root_path / category\n",
    "            files = list(category_path.glob('*'))\n",
    "            \n",
    "            if max_samples_per_category:\n",
    "                files = files[:max_samples_per_category]\n",
    "            \n",
    "            for file_path in files:\n",
    "                if file_path.is_file():\n",
    "                    try:\n",
    "                        # Read file with encoding handling\n",
    "                        with open(file_path, 'rb') as f:\n",
    "                            raw = f.read()\n",
    "                        \n",
    "                        try:\n",
    "                            text = raw.decode('utf-8').strip()\n",
    "                        except UnicodeDecodeError:\n",
    "                            text = raw.decode('latin-1').strip()\n",
    "                        \n",
    "                        # APPLY CLEANING\n",
    "                        cleaned_text = clean_20_news(text)\n",
    "                        \n",
    "                        # Only add if content remains after cleaning\n",
    "                        if cleaned_text and len(cleaned_text) > 50:\n",
    "                            texts.append(cleaned_text)\n",
    "                            labels.append(category)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_path}: {e}\")\n",
    "        \n",
    "        print(f\"\\nTotal loaded documents: {len(texts)}\")\n",
    "        print(f\"Category distribution:\")\n",
    "        label_counts = Counter(labels)\n",
    "        for label, count in sorted(label_counts.items()):\n",
    "            print(f\"  {label}: {count}\")\n",
    "        \n",
    "        return texts, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dataset Multi-Domain Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDomainSentimentLoader:\n",
    "    \"\"\"\n",
    "    Class for loading and processing the Multi-Domain Sentiment Dataset with enhanced cleaning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_path: str):\n",
    "        \"\"\"\n",
    "        Initializes the loader.\n",
    "        \n",
    "        Args:\n",
    "            root_path: Path to the dataset’s root directory\n",
    "        \"\"\"\n",
    "        self.root_path = Path(root_path)\n",
    "        self.domains = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "        \n",
    "    def _parse_review_line(self, line: str) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Parses a review line from the file.\n",
    "        \n",
    "        Format: word1:freq1 word2:freq2 ... #label#:positive/negative\n",
    "        \n",
    "        Args:\n",
    "            line: Line of the file\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (reconstructed_text, label)\n",
    "        \"\"\"\n",
    "        parts = line.strip().split()\n",
    "        \n",
    "        label = None\n",
    "        words = []\n",
    "        \n",
    "        for part in parts:\n",
    "            if part.startswith('#label#:'):\n",
    "                label = part.split(':')[1]\n",
    "            else:\n",
    "                if ':' in part:\n",
    "                    word, freq = part.rsplit(':', 1)\n",
    "                    try:\n",
    "                        freq = int(freq)\n",
    "                        # Simplification: use each word once\n",
    "                        words.append(word)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        \n",
    "        # Reconstruct text\n",
    "        text = ' '.join(words)\n",
    "        \n",
    "        # APPLY CLEANING\n",
    "        cleaned_text = clean_multidomain(text)\n",
    "        \n",
    "        return cleaned_text, label\n",
    "    \n",
    "    def load_domain_data(self, domain: str, sentiment: str, \n",
    "                         max_samples: Optional[int] = None) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Loads data for a specific domain and sentiment.\n",
    "        \n",
    "        Args:\n",
    "            domain: Domain name\n",
    "            sentiment: Sentiment type ('positive' or 'negative')\n",
    "            max_samples: Maximum number of samples to load\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (clean_texts, labels)\n",
    "        \"\"\"\n",
    "        file_path = self.root_path / domain / f\"{sentiment}.review\"\n",
    "        \n",
    "        texts = []\n",
    "        labels = []\n",
    "        \n",
    "        if not file_path.exists():\n",
    "            print(f\"Warning: {file_path} not found\")\n",
    "            return texts, labels\n",
    "        \n",
    "        with open(file_path, 'r', encoding='latin-1') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            if max_samples:\n",
    "                lines = lines[:max_samples]\n",
    "            \n",
    "            for line in lines:\n",
    "                text, label = self._parse_review_line(line)\n",
    "                if text and label and len(text) > 20:  # Filter very short texts\n",
    "                    texts.append(text)\n",
    "                    labels.append(label)\n",
    "        \n",
    "        return texts, labels\n",
    "    \n",
    "    def load_all_data(self, max_samples_per_sentiment: Optional[int] = None) -> Tuple[List[str], List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Loads all data from all domains.\n",
    "        \n",
    "        Args:\n",
    "            max_samples_per_sentiment: Maximum samples per sentiment in each domain\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (clean_texts, labels, domains)\n",
    "        \"\"\"\n",
    "        all_texts = []\n",
    "        all_labels = []\n",
    "        all_domains = []\n",
    "        \n",
    "        print(f\"Loading Multi-Domain Sentiment from: {self.root_path}\")\n",
    "        \n",
    "        for domain in tqdm(self.domains, desc=\"Processing domains\"):\n",
    "            for sentiment in ['positive', 'negative']:\n",
    "                texts, labels = self.load_domain_data(domain, sentiment, max_samples_per_sentiment)\n",
    "                all_texts.extend(texts)\n",
    "                all_labels.extend(labels)\n",
    "                all_domains.extend([domain] * len(texts))\n",
    "                \n",
    "                print(f\"  {domain}/{sentiment}: {len(texts)} samples\")\n",
    "        \n",
    "        print(f\"\\nTotal reviews loaded: {len(all_texts)}\")\n",
    "        print(f\"Sentiment distribution:\")\n",
    "        label_counts = Counter(all_labels)\n",
    "        for label, count in label_counts.items():\n",
    "            print(f\"  {label}: {count}\")\n",
    "        \n",
    "        return all_texts, all_labels, all_domains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classifier Implementations\n",
    "\n",
    "This class uses preprocessed texts for improved classification. Here we implement both a class for GPT-2 and another for Gemma2.\n",
    "\n",
    "Given the extremely poor baseline performance of decoder-only models on the 20Newsgroups dataset—where GPT-2 (124M) and GPT-2-XL (1.5B) achieved accuracies close to random guessing,prompt engineering became essential to guide the model toward the actual classification task. The prompts were redesigned to include three core elements: (1) a minimal task-specific context describing the dataset and the type of text the model would receive, (2) short, carefully selected few-shot examples to anchor the expected output format, and (3) concise phrasing to avoid unnecessary token consumption and to preserve space within the limited context window of decoder-only models. \n",
    "\n",
    "The contextual description helps the model understand that 20Newsgroups posts correspond to forum discussions across specific topical categories, which is not obvious from the raw text alone. The few-shot examples provide explicit demonstrations of how a message maps to a category, reducing ambiguity and forcing the model to mimic the desired output format. Finally, keeping the instructions short ensures that the prompt remains efficient and that the classifier focuses on the essential classification signal rather than being overwhelmed by long instructions or excessive examples. These design decisions directly address the observed failures and aim to improve the model’s ability to distinguish between the highly heterogeneous categories in 20Newsgroups.\n",
    "\n",
    "Below are the previous results obtained without the prompt improvements listed above:\n",
    "\n",
    "| Model           | Preprocessing | Task         | Accuracy | F1 Macro | F1 Micro |\n",
    "| --------------- | ------------- | ------------ | -------- | -------- | -------- |\n",
    "| GPT-2 (124M)    | With cleaning | Sentiment    | 0.501250 | 0.336105 | 0.501250 |\n",
    "| GPT-2-XL (1.5B) | With cleaning | Sentiment    | 0.500000 | 0.333333 | 0.500000 |\n",
    "| GPT-2 (124M)    | With cleaning | 20Newsgroups | 0.056509 | 0.029406 | 0.056509 |\n",
    "| GPT-2-XL (1.5B) | With cleaning | 20Newsgroups | 0.058527 | 0.029013 | 0.058527 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Classifier:\n",
    "    \"\"\"\n",
    "    Classifier based on GPT-2 models using prompting without fine-tuning.\n",
    "    \n",
    "    It now uses PREPROCESSED texts for better performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"gpt2\", device: str = \"cuda\"):\n",
    "        \"\"\"\n",
    "        Initializes the GPT-2 classifier.\n",
    "        \n",
    "        Args:\n",
    "            model_name: GPT-2 model name ('gpt2', 'gpt2-xl')\n",
    "            device: Device to run the model on\n",
    "        \"\"\"\n",
    "        print(f\"\\nLoading model: {model_name}\")\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Configure pad token\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        print(f\"Model successfully loaded on {device}\")\n",
    "        print(f\"Number of parameters: {self.model.num_parameters() / 1e6:.1f}M\")\n",
    "    \n",
    "    def create_prompt(self, text: str, task_type: str, categories: List[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Creates an improved task-specific classification prompt with dataset context,\n",
    "        short examples, and clearer instructions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Truncate long texts\n",
    "        max_text_length = 512\n",
    "        if len(text) > max_text_length:\n",
    "            text = text[:max_text_length] + \"...\"\n",
    "\n",
    "        # -----------------------------\n",
    "        # SENTIMENT ANALYSIS (MDSD)\n",
    "        # -----------------------------\n",
    "        if task_type == 'sentiment':\n",
    "            prompt = (\n",
    "                \"You will classify product reviews from the Multi-Domain Sentiment Dataset.\\n\"\n",
    "                \"Each review expresses either a positive or a negative opinion.\\n\"\n",
    "                \"A positive review indicates satisfaction, good quality, or a good experience.\\n\"\n",
    "                \"A negative review indicates dissatisfaction, poor quality, or a bad experience.\\n\"\n",
    "                \"Respond using only the words 'positive' or 'negative'.\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Review: The product arrived broken and stopped working immediately.\\n\"\n",
    "                \"Sentiment: negative\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Review: Excellent quality, works perfectly and exceeded expectations.\\n\"\n",
    "                \"Sentiment: positive\\n\\n\"\n",
    "                f\"Review: {text}\\n\"\n",
    "                \"Sentiment:\"\n",
    "            )\n",
    "\n",
    "        # -----------------------------\n",
    "        # 20 NEWSGROUPS\n",
    "        # -----------------------------\n",
    "        elif task_type == 'newsgroups':\n",
    "\n",
    "            if not categories or len(categories) == 0:\n",
    "                raise ValueError(\"Categories list is required for newsgroups classification.\")\n",
    "\n",
    "            # Usenet context + instruction to answer with 1 label\n",
    "            prompt = (\n",
    "                \"You will classify a message from the 20 Newsgroups dataset.\\n\"\n",
    "                \"These messages come from online forum discussions (Usenet) across different topics.\\n\"\n",
    "                \"Your task is to identify the single category that best matches the main topic.\\n\"\n",
    "                \"Respond using only one category name from the list.\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Message: I installed the new drivers for my video card and now my system keeps freezing.\\n\"\n",
    "                \"Category: comp.os.ms-windows.misc\\n\\n\"\n",
    "                \"Available categories:\\n\"\n",
    "                f\"{', '.join(categories)}\\n\\n\"\n",
    "                f\"Message: {text}\\n\"\n",
    "                \"Category:\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    \n",
    "    def generate_completion(self, prompt: str, max_new_tokens: int = 20) -> str:\n",
    "        \"\"\"\n",
    "        Generates a completion for the given prompt.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Input prompt\n",
    "            max_new_tokens: Maximum number of tokens to generate\n",
    "            \n",
    "        Returns:\n",
    "            Generated text\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            \n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                do_sample=False,\n",
    "                temperature=1.0\n",
    "            )\n",
    "            \n",
    "            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            completion = generated_text[len(prompt):].strip()\n",
    "            \n",
    "        return completion\n",
    "    \n",
    "    def extract_label_from_completion(self, completion: str, valid_labels: List[str], \n",
    "                                     task_type: str = 'sentiment') -> str:\n",
    "        \"\"\"\n",
    "        Extracts the predicted label from the generated text.\n",
    "        \n",
    "        Args:\n",
    "            completion: Generated model output\n",
    "            valid_labels: List of valid labels\n",
    "            task_type: Task type\n",
    "            \n",
    "        Returns:\n",
    "            Extracted label\n",
    "        \"\"\"\n",
    "        completion_lower = completion.lower()\n",
    "        first_line = completion.split('\\n')[0]\n",
    "        first_words = ' '.join(first_line.split()[:5]).lower()\n",
    "        \n",
    "        if task_type == 'sentiment':\n",
    "            if 'positive' in first_words or 'good' in first_words or 'great' in first_words:\n",
    "                return 'positive'\n",
    "            elif 'negative' in first_words or 'bad' in first_words or 'poor' in first_words:\n",
    "                return 'negative'\n",
    "            else:\n",
    "                first_word = first_line.split()[0].lower() if first_line.split() else ''\n",
    "                if 'pos' in first_word:\n",
    "                    return 'positive'\n",
    "                elif 'neg' in first_word:\n",
    "                    return 'negative'\n",
    "                else:\n",
    "                    return 'positive'\n",
    "        \n",
    "        else:  # newsgroups\n",
    "            for label in valid_labels:\n",
    "                label_parts = label.split('.')\n",
    "                for part in label_parts:\n",
    "                    if part.lower() in first_words:\n",
    "                        return label\n",
    "            \n",
    "            best_match = None\n",
    "            max_overlap = 0\n",
    "            \n",
    "            for label in valid_labels:\n",
    "                label_words = set(label.lower().replace('.', ' ').split())\n",
    "                completion_words = set(first_words.split())\n",
    "                overlap = len(label_words & completion_words)\n",
    "                \n",
    "                if overlap > max_overlap:\n",
    "                    max_overlap = overlap\n",
    "                    best_match = label\n",
    "            \n",
    "            return best_match if best_match else valid_labels[0]\n",
    "    \n",
    "    def predict(self, texts: List[str], task_type: str, \n",
    "                valid_labels: List[str], batch_size: int = 1) -> List[str]:\n",
    "        \"\"\"\n",
    "        Predicts labels for a list of clean texts.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of CLEAN texts to classify\n",
    "            task_type: Type of task\n",
    "            valid_labels: List of valid labels\n",
    "            batch_size: Batch size\n",
    "            \n",
    "        Returns:\n",
    "            List of predictions\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        print(f\"\\nRunning predictions with {self.model_name}...\")\n",
    "        \n",
    "        for text in tqdm(texts, desc=\"Classifying\"):\n",
    "            prompt = self.create_prompt(text, task_type, valid_labels)\n",
    "            completion = self.generate_completion(prompt)\n",
    "            label = self.extract_label_from_completion(completion, valid_labels, task_type)\n",
    "            predictions.append(label)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemma2Classifier:\n",
    "    \"\"\"\n",
    "    Classifier based on prompting without fine-tuning.\n",
    "    Compatible with Gemma 2 (2B/2B-it) loaded via Transformers.\n",
    "    Preserves the same prompt style and label extraction logic\n",
    "    as the original GPT-2 snippet.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = None,\n",
    "        device: str = None,\n",
    "        tokenizer: AutoTokenizer = None,\n",
    "        model: AutoModelForCausalLM = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: HF model ID (e.g. \"google/gemma-2-2b\" or \"google/gemma-2-2b-it\").\n",
    "            device: \"cuda\" or \"cpu\" (if None, auto-detect).\n",
    "            tokenizer: Optional preloaded tokenizer.\n",
    "            model: Optional preloaded model.\n",
    "        \"\"\"\n",
    "        # Device selection\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Reuse provided or global objects\n",
    "        if tokenizer is not None and model is not None:\n",
    "            self.tokenizer = tokenizer\n",
    "            self.model = model\n",
    "            self.model_name = getattr(model.config, \"name_or_path\", \"gemma2\")\n",
    "        else:\n",
    "            if \"tokenizer\" in globals() and \"model\" in globals():\n",
    "                self.tokenizer = globals()[\"tokenizer\"]\n",
    "                self.model = globals()[\"model\"]\n",
    "                self.model_name = getattr(self.model.config, \"name_or_path\", \"gemma2\")\n",
    "            else:\n",
    "                if model_name is None:\n",
    "                    model_name = \"google/gemma-2-2b\"\n",
    "                print(f\"\\nLoading model: {model_name}\")\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    model_name,\n",
    "                    trust_remote_code=True\n",
    "                )\n",
    "\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Ensure pad token\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        print(f\"Model '{self.model_name}' ready on {self.device}\")\n",
    "        try:\n",
    "            print(f\"Number of parameters: {self.model.num_parameters() / 1e6:.1f}M\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    def create_prompt(self, text: str, task_type: str, categories: List[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Creates an improved task-specific classification prompt with dataset context,\n",
    "        short examples, and clearer instructions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Truncate long texts\n",
    "        max_text_length = 350\n",
    "        if len(text) > max_text_length:\n",
    "            text = text[:max_text_length] + \"...\"\n",
    "\n",
    "        # -----------------------------\n",
    "        # SENTIMENT ANALYSIS (MDSD)\n",
    "        # -----------------------------\n",
    "        if task_type == 'sentiment':\n",
    "            prompt = (\n",
    "                \"You will classify product reviews from the Multi-Domain Sentiment Dataset.\\n\"\n",
    "                \"Each review expresses either a positive or a negative opinion.\\n\"\n",
    "                \"A positive review indicates satisfaction, good quality, or a good experience.\\n\"\n",
    "                \"A negative review indicates dissatisfaction, poor quality, or a bad experience.\\n\"\n",
    "                \"Respond using only the words 'positive' or 'negative'.\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Review: The product arrived broken and stopped working immediately.\\n\"\n",
    "                \"Sentiment: negative\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Review: Excellent quality, works perfectly and exceeded expectations.\\n\"\n",
    "                \"Sentiment: positive\\n\\n\"\n",
    "                f\"Review: {text}\\n\"\n",
    "                \"Sentiment:\"\n",
    "            )\n",
    "\n",
    "        # -----------------------------\n",
    "        # 20 NEWSGROUPS\n",
    "        # -----------------------------\n",
    "        elif task_type == 'newsgroups':\n",
    "\n",
    "            if not categories or len(categories) == 0:\n",
    "                raise ValueError(\"Categories list is required for newsgroups classification.\")\n",
    "\n",
    "            # Usenet context + instruction to answer with 1 label\n",
    "            prompt = (\n",
    "                \"You will classify a message from the 20 Newsgroups dataset.\\n\"\n",
    "                \"These messages come from online forum discussions (Usenet) across different topics.\\n\"\n",
    "                \"Your task is to identify the single category that best matches the main topic.\\n\"\n",
    "                \"Respond using only one category name from the list.\\n\\n\"\n",
    "                \"Example:\\n\"\n",
    "                \"Message: I installed the new drivers for my video card and now my system keeps freezing.\\n\"\n",
    "                \"Category: comp.os.ms-windows.misc\\n\\n\"\n",
    "                \"Available categories:\\n\"\n",
    "                f\"{', '.join(categories)}\\n\\n\"\n",
    "                f\"Message: {text}\\n\"\n",
    "                \"Category:\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "\n",
    "        return prompt\n",
    "\n",
    "\n",
    "    def generate_completion(self, prompt: str, max_new_tokens: int = 20) -> str:\n",
    "        \"\"\"\n",
    "        Generates continuation for the given prompt (greedy decoding,\n",
    "        same behavior as the original implementation).\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                do_sample=False,\n",
    "                temperature=1.0\n",
    "            )\n",
    "\n",
    "            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        if generated_text.startswith(prompt):\n",
    "            completion = generated_text[len(prompt):].strip()\n",
    "        else:\n",
    "            anchor = \"Category:\" if \"Category:\" in prompt else \"Sentiment:\"\n",
    "            completion = generated_text.split(anchor)[-1].strip()\n",
    "\n",
    "        return completion\n",
    "\n",
    "    def extract_label_from_completion(\n",
    "        self,\n",
    "        completion: str,\n",
    "        valid_labels: List[str],\n",
    "        task_type: str = \"sentiment\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Extracts the label from the first line/words of the output.\n",
    "        Same logic as the original snippet.\n",
    "        \"\"\"\n",
    "        first_line = completion.split(\"\\n\")[0]\n",
    "        first_words = \" \".join(first_line.split()[:5]).lower()\n",
    "\n",
    "        if task_type == \"sentiment\":\n",
    "            if any(x in first_words for x in [\"positive\", \"good\", \"great\"]):\n",
    "                return \"positive\"\n",
    "            if any(x in first_words for x in [\"negative\", \"bad\", \"poor\"]):\n",
    "                return \"negative\"\n",
    "            first_word = first_line.split()[0].lower() if first_line.split() else \"\"\n",
    "            if \"pos\" in first_word:\n",
    "                return \"positive\"\n",
    "            if \"neg\" in first_word:\n",
    "                return \"negative\"\n",
    "            return \"positive\"\n",
    "\n",
    "        else:  # newsgroups\n",
    "            for label in valid_labels:\n",
    "                for part in label.split(\".\"):\n",
    "                    if part.lower() in first_words:\n",
    "                        return label\n",
    "\n",
    "            best_match, max_overlap = None, 0\n",
    "            completion_words = set(first_words.split())\n",
    "            for label in valid_labels:\n",
    "                label_words = set(label.lower().replace(\".\", \" \").split())\n",
    "                overlap = len(label_words & completion_words)\n",
    "                if overlap > max_overlap:\n",
    "                    max_overlap = overlap\n",
    "                    best_match = label\n",
    "\n",
    "            return best_match if best_match else valid_labels[0]\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        task_type: str,\n",
    "        valid_labels: List[str],\n",
    "        batch_size: int = 1\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Classifies a list of clean texts using prompting.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        print(f\"\\nRunning predictions with {getattr(self.model.config, 'name_or_path', 'gemma2')}...\")\n",
    "\n",
    "        for text in tqdm(texts, desc=\"Classifying\"):\n",
    "            prompt = self.create_prompt(text, task_type, valid_labels)\n",
    "            completion = self.generate_completion(prompt)\n",
    "            label = self.extract_label_from_completion(completion, valid_labels, task_type)\n",
    "            predictions.append(label)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "\n",
    "def evaluate_classifier(y_true: List[str], y_pred: List[str], \n",
    "                       label_names: List[str] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluates classifier performance.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels\n",
    "        label_names: Label names\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with metrics\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    report = classification_report(y_true, y_pred, target_names=label_names, zero_division=0)\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_micro': recall_micro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'report': report\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_results(results: Dict, model_name: str, task_name: str):\n",
    "    \"\"\"\n",
    "    Prints evaluation results.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Results: {model_name} - {task_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nAccuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"\\nMacro Metrics:\")\n",
    "    print(f\"  Precision: {results['precision_macro']:.4f}\")\n",
    "    print(f\"  Recall:    {results['recall_macro']:.4f}\")\n",
    "    print(f\"  F1-Score:  {results['f1_macro']:.4f}\")\n",
    "    print(f\"\\nMicro Metrics:\")\n",
    "    print(f\"  Precision: {results['precision_micro']:.4f}\")\n",
    "    print(f\"  Recall:    {results['recall_micro']:.4f}\")\n",
    "    print(f\"  F1-Score:  {results['f1_micro']:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(results['report'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiments\n",
    "\n",
    "The experiments consisted of evaluating decoder-only language models on two text classification tasks using cleaned versions of the Multi-Domain Sentiment dataset and the 20Newsgroups corpus. For each dataset, three models were tested: GPT-2 (124M), GPT-2-XL (1.5B), and Gemma-2, all used without fine-tuning and relying solely on prompting. The procedure involved loading and preprocessing the datasets, generating predictions through task-specific prompts, and computing standard evaluation metrics including accuracy and F1 scores.\n",
    "\n",
    "### 5.1 Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACIÓN\n",
    "NEWSGROUPS_PATH = \"20news-18828\"  \n",
    "SENTIMENT_PATH = \"processed_acl\"  \n",
    "\n",
    "# Parámetros para limitar el tamaño (ajustar según recursos)\n",
    "MAX_SAMPLES_NEWSGROUPS = 50  # Por categoría\n",
    "MAX_SAMPLES_SENTIMENT = 100  # Por sentimiento/dominio\n",
    "\n",
    "# Para experimento completo:\n",
    "# MAX_SAMPLES_NEWSGROUPS = None\n",
    "# MAX_SAMPLES_SENTIMENT = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Load Data and Split Data (with automatic cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADING AND CLEANING MULTI-DOMAIN SENTIMENT\n",
      "================================================================================\n",
      "Loading Multi-Domain Sentiment from: processed_acl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing domains:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing domains: 100%|██████████| 4/4 [00:00<00:00, 23.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  books/positive: 100 samples\n",
      "  books/negative: 100 samples\n",
      "  dvd/positive: 100 samples\n",
      "  dvd/negative: 100 samples\n",
      "  electronics/positive: 100 samples\n",
      "  electronics/negative: 100 samples\n",
      "  kitchen/positive: 100 samples\n",
      "  kitchen/negative: 100 samples\n",
      "\n",
      "Total reviews loaded: 800\n",
      "Sentiment distribution:\n",
      "  positive: 400\n",
      "  negative: 400\n",
      "\n",
      "Clean dataset:\n",
      "Total: 800 samples\n",
      "\n",
      "Example of cleaned text:\n",
      "holes must top secret he center other civilans the pacific the navy a lot surface must this book man named feet would strongly put down norman johnson lawes a top the support ten on random typhoon a p...\n",
      "\n",
      "Train size: 480\n",
      "Val size:   80\n",
      "Test size:  240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar Multi-Domain Sentiment con limpieza\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING AND CLEANING MULTI-DOMAIN SENTIMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load cleaned dataset\n",
    "sentiment_loader = MultiDomainSentimentLoader(SENTIMENT_PATH)\n",
    "texts_sentiment, labels_sentiment, domains_sentiment = sentiment_loader.load_all_data(\n",
    "    max_samples_per_sentiment=MAX_SAMPLES_SENTIMENT\n",
    ")\n",
    "\n",
    "print(f\"\\nClean dataset:\")\n",
    "print(f\"Total: {len(texts_sentiment)} samples\")\n",
    "print(f\"\\nExample of cleaned text:\")\n",
    "print(f\"{texts_sentiment[0][:200]}...\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 60% train, 40% temp\n",
    "# ---------------------------------------------------------------------\n",
    "X_train_sent, X_temp, y_train_sent, y_temp = train_test_split(\n",
    "    texts_sentiment,\n",
    "    labels_sentiment,\n",
    "    test_size=0.4,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=labels_sentiment  # keep positive/negative balance\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# From 40% temp → 10% val, 30% test\n",
    "# (val = 25% of temp, test = 75% of temp)\n",
    "# ---------------------------------------------------------------------\n",
    "X_val_sent, X_test_sent, y_val_sent, y_test_sent = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.75,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Build DataFrames (fixing your previous issue)\n",
    "# ---------------------------------------------------------------------\n",
    "train_sent_df = pd.DataFrame({\"text\": X_train_sent, \"label\": y_train_sent})\n",
    "val_sent_df   = pd.DataFrame({\"text\": X_val_sent,   \"label\": y_val_sent})\n",
    "test_sent_df  = pd.DataFrame({\"text\": X_test_sent,  \"label\": y_test_sent})\n",
    "\n",
    "print(f\"\\nTrain size: {len(train_sent_df)}\")\n",
    "print(f\"Val size:   {len(val_sent_df)}\")\n",
    "print(f\"Test size:  {len(test_sent_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADING AND CLEANING 20NEWSGROUPS\n",
      "================================================================================\n",
      "Loading 20Newsgroups from: 20news-18828\n",
      "Categories found: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories: 100%|██████████| 20/20 [00:00<00:00, 69.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total loaded documents: 991\n",
      "Category distribution:\n",
      "  alt.atheism: 50\n",
      "  comp.graphics: 50\n",
      "  comp.os.ms-windows.misc: 49\n",
      "  comp.sys.ibm.pc.hardware: 50\n",
      "  comp.sys.mac.hardware: 48\n",
      "  comp.windows.x: 49\n",
      "  misc.forsale: 50\n",
      "  rec.autos: 50\n",
      "  rec.motorcycles: 48\n",
      "  rec.sport.baseball: 50\n",
      "  rec.sport.hockey: 50\n",
      "  sci.crypt: 50\n",
      "  sci.electronics: 49\n",
      "  sci.med: 49\n",
      "  sci.space: 50\n",
      "  soc.religion.christian: 50\n",
      "  talk.politics.guns: 50\n",
      "  talk.politics.mideast: 50\n",
      "  talk.politics.misc: 49\n",
      "  talk.religion.misc: 50\n",
      "Train size: 594\n",
      "Val size:   99\n",
      "Test size:  298\n",
      "\n",
      "Clean dataset:\n",
      "Total: 991 documents\n",
      "Categories: 20\n",
      "\n",
      "Example of cleaned text:\n",
      "One thing I think is interesting about alt.athiesm is the fact that without bible-thumpers and their ilk this would be a much duller newsgroup. It almost needs the deluded masses to write silly things...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING AND CLEANING 20NEWSGROUPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "newsgroups_loader = NewsGroupsLoader(NEWSGROUPS_PATH)\n",
    "texts_newsgroups, labels_newsgroups = newsgroups_loader.load_data(\n",
    "    max_samples_per_category=MAX_SAMPLES_NEWSGROUPS\n",
    ")\n",
    "\n",
    "# 60% for training, 40% for second split\n",
    "X_train_20news, X_temp_20news, y_train_20news, y_temp_20news = train_test_split(\n",
    "    texts_newsgroups,\n",
    "    labels_newsgroups,\n",
    "    test_size=0.4,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=labels_newsgroups\n",
    ")\n",
    "\n",
    "# 10% for validation, 30% for test\n",
    "X_val_20news, X_test_20news, y_val_20news, y_test_20news = train_test_split(\n",
    "    X_temp_20news,\n",
    "    y_temp_20news,\n",
    "    test_size=0.75,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y_temp_20news\n",
    ")\n",
    "\n",
    "train_20news_df = pd.DataFrame({\"text\": X_train_20news, \"label\": y_train_20news})\n",
    "val_20news_df   = pd.DataFrame({\"text\": X_val_20news,   \"label\": y_val_20news})\n",
    "test_20news_df  = pd.DataFrame({\"text\": X_test_20news,  \"label\": y_test_20news})\n",
    "\n",
    "print(f\"Train size: {len(train_20news_df)}\")\n",
    "print(f\"Val size:   {len(val_20news_df)}\")\n",
    "print(f\"Test size:  {len(test_20news_df)}\")\n",
    "\n",
    "unique_categories = sorted(list(set(labels_newsgroups)))\n",
    "\n",
    "print(f\"\\nClean dataset:\")\n",
    "print(f\"Total: {len(texts_newsgroups)} documents\")\n",
    "print(f\"Categories: {len(unique_categories)}\")\n",
    "print(f\"\\nExample of cleaned text:\")\n",
    "print(f\"{texts_newsgroups[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Experimento 1: Sentiment Analysis con GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model: gpt2\n",
      "Model successfully loaded on cuda\n",
      "Number of parameters: 124.4M\n",
      "\n",
      "Running predictions with gpt2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 240/240 [00:39<00:00,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Results: GPT-2 (with preprocessing) - Sentiment Analysis\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.5125\n",
      "\n",
      "Macro Metrics:\n",
      "  Precision: 0.7532\n",
      "  Recall:    0.5125\n",
      "  F1-Score:  0.3605\n",
      "\n",
      "Micro Metrics:\n",
      "  Precision: 0.5125\n",
      "  Recall:    0.5125\n",
      "  F1-Score:  0.5125\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.03      0.05       120\n",
      "    positive       0.51      1.00      0.67       120\n",
      "\n",
      "    accuracy                           0.51       240\n",
      "   macro avg       0.75      0.51      0.36       240\n",
      "weighted avg       0.75      0.51      0.36       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPT-2\n",
    "gpt2_classifier = GPT2Classifier(model_name=\"gpt2\", device=device)\n",
    "\n",
    "# Predictions\n",
    "predictions_gpt2_sentiment = gpt2_classifier.predict(\n",
    "    texts=X_test_sent,\n",
    "    task_type='sentiment',\n",
    "    valid_labels=['positive', 'negative']\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "results_gpt2_sentiment = evaluate_classifier(\n",
    "    y_true=y_test_sent,\n",
    "    y_pred=predictions_gpt2_sentiment,\n",
    "    label_names=['negative', 'positive']\n",
    ")\n",
    "\n",
    "print_results(results_gpt2_sentiment, \"GPT-2 (with preprocessing)\", \"Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Experiment 2: Sentiment Analysis with GPT-2-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model: gpt2-xl\n",
      "Model successfully loaded on cuda\n",
      "Number of parameters: 1557.6M\n",
      "\n",
      "Running predictions with gpt2-xl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 240/240 [02:19<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Results: GPT-2-XL (with preprocessing) - Sentiment Analysis\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.5500\n",
      "\n",
      "Macro Metrics:\n",
      "  Precision: 0.7276\n",
      "  Recall:    0.5500\n",
      "  F1-Score:  0.4409\n",
      "\n",
      "Micro Metrics:\n",
      "  Precision: 0.5500\n",
      "  Recall:    0.5500\n",
      "  F1-Score:  0.5500\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.11      0.19       120\n",
      "    positive       0.53      0.99      0.69       120\n",
      "\n",
      "    accuracy                           0.55       240\n",
      "   macro avg       0.73      0.55      0.44       240\n",
      "weighted avg       0.73      0.55      0.44       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPT-2-XL\n",
    "gpt2xl_classifier = GPT2Classifier(model_name=\"gpt2-xl\", device=device)\n",
    "\n",
    "# Predictions\n",
    "predictions_gpt2xl_sentiment = gpt2xl_classifier.predict(\n",
    "    texts=X_test_sent,\n",
    "    task_type='sentiment',\n",
    "    valid_labels=['positive', 'negative']\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "results_gpt2xl_sentiment = evaluate_classifier(\n",
    "    y_true=y_test_sent,\n",
    "    y_pred=predictions_gpt2xl_sentiment,\n",
    "    label_names=['negative', 'positive']\n",
    ")\n",
    "\n",
    "print_results(results_gpt2xl_sentiment, \"GPT-2-XL (with preprocessing)\", \"Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Experiment 4: Sentiment Analysis with Gemma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'google/gemma-2-2b' ready on cuda\n",
      "Number of parameters: 2614.3M\n",
      "\n",
      "Running predictions with google/gemma-2-2b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying:   0%|          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 240/240 [03:33<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Results: Gemma2 (with preprocessing) - Sentiment Analysis\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.6042\n",
      "\n",
      "Macro Metrics:\n",
      "  Precision: 0.6914\n",
      "  Recall:    0.6042\n",
      "  F1-Score:  0.5533\n",
      "\n",
      "Micro Metrics:\n",
      "  Precision: 0.6042\n",
      "  Recall:    0.6042\n",
      "  F1-Score:  0.6042\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.27      0.40       120\n",
      "    positive       0.56      0.94      0.70       120\n",
      "\n",
      "    accuracy                           0.60       240\n",
      "   macro avg       0.69      0.60      0.55       240\n",
      "weighted avg       0.69      0.60      0.55       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemma2\n",
    "gemma2_classifier = Gemma2Classifier(device=\"cuda\")\n",
    "\n",
    "# Predictions\n",
    "predictions_gemma2_sentiment = gemma2_classifier.predict(\n",
    "    texts=X_test_sent,\n",
    "    task_type='sentiment',\n",
    "    valid_labels=['positive', 'negative']\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "results_gemma2_sentiment = evaluate_classifier(\n",
    "    y_true=y_test_sent,\n",
    "    y_pred=predictions_gemma2_sentiment,\n",
    "    label_names=['negative', 'positive']\n",
    ")\n",
    "\n",
    "print_results(results_gemma2_sentiment, \"Gemma2 (with preprocessing)\", \"Sentiment Analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Experiment 4: 20Newsgroups with GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running predictions with gpt2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 298/298 [00:49<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Results: GPT-2 (con preprocesamiento) - 20Newsgroups\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.0537\n",
      "\n",
      "Macro Metrics:\n",
      "  Precision: 0.0525\n",
      "  Recall:    0.0533\n",
      "  F1-Score:  0.0111\n",
      "\n",
      "Micro Metrics:\n",
      "  Precision: 0.0537\n",
      "  Recall:    0.0537\n",
      "  F1-Score:  0.0537\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00        15\n",
      "           comp.graphics       0.05      1.00      0.10        15\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00        15\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00        15\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00        15\n",
      "          comp.windows.x       0.00      0.00      0.00        15\n",
      "            misc.forsale       0.00      0.00      0.00        15\n",
      "               rec.autos       0.00      0.00      0.00        15\n",
      "         rec.motorcycles       0.00      0.00      0.00        14\n",
      "      rec.sport.baseball       0.00      0.00      0.00        15\n",
      "        rec.sport.hockey       0.00      0.00      0.00        15\n",
      "               sci.crypt       0.00      0.00      0.00        15\n",
      "         sci.electronics       0.00      0.00      0.00        15\n",
      "                 sci.med       0.00      0.00      0.00        15\n",
      "               sci.space       0.00      0.00      0.00        15\n",
      "  soc.religion.christian       1.00      0.07      0.12        15\n",
      "      talk.politics.guns       0.00      0.00      0.00        15\n",
      "   talk.politics.mideast       0.00      0.00      0.00        15\n",
      "      talk.politics.misc       0.00      0.00      0.00        14\n",
      "      talk.religion.misc       0.00      0.00      0.00        15\n",
      "\n",
      "                accuracy                           0.05       298\n",
      "               macro avg       0.05      0.05      0.01       298\n",
      "            weighted avg       0.05      0.05      0.01       298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicciones\n",
    "predictions_gpt2_newsgroups = gpt2_classifier.predict(\n",
    "    texts=X_test_20news,\n",
    "    task_type='newsgroups',\n",
    "    valid_labels=unique_categories\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "results_gpt2_newsgroups = evaluate_classifier(\n",
    "    y_true=y_test_20news,\n",
    "    y_pred=predictions_gpt2_newsgroups,\n",
    "    label_names=unique_categories\n",
    ")\n",
    "\n",
    "print_results(results_gpt2_newsgroups, \"GPT-2 (con preprocesamiento)\", \"20Newsgroups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Experiment 5: 20Newsgroups with GPT-2-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running predictions with gpt2-xl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 298/298 [03:03<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Results: GPT-2-XL (with preprocessing) - 20Newsgroups\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.0537\n",
      "\n",
      "Macro Metrics:\n",
      "  Precision: 0.0194\n",
      "  Recall:    0.0533\n",
      "  F1-Score:  0.0107\n",
      "\n",
      "Micro Metrics:\n",
      "  Precision: 0.0537\n",
      "  Recall:    0.0537\n",
      "  F1-Score:  0.0537\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00        15\n",
      "           comp.graphics       0.05      1.00      0.10        15\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00        15\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00        15\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00        15\n",
      "          comp.windows.x       0.00      0.00      0.00        15\n",
      "            misc.forsale       0.00      0.00      0.00        15\n",
      "               rec.autos       0.00      0.00      0.00        15\n",
      "         rec.motorcycles       0.00      0.00      0.00        14\n",
      "      rec.sport.baseball       0.33      0.07      0.11        15\n",
      "        rec.sport.hockey       0.00      0.00      0.00        15\n",
      "               sci.crypt       0.00      0.00      0.00        15\n",
      "         sci.electronics       0.00      0.00      0.00        15\n",
      "                 sci.med       0.00      0.00      0.00        15\n",
      "               sci.space       0.00      0.00      0.00        15\n",
      "  soc.religion.christian       0.00      0.00      0.00        15\n",
      "      talk.politics.guns       0.00      0.00      0.00        15\n",
      "   talk.politics.mideast       0.00      0.00      0.00        15\n",
      "      talk.politics.misc       0.00      0.00      0.00        14\n",
      "      talk.religion.misc       0.00      0.00      0.00        15\n",
      "\n",
      "                accuracy                           0.05       298\n",
      "               macro avg       0.02      0.05      0.01       298\n",
      "            weighted avg       0.02      0.05      0.01       298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicciones\n",
    "predictions_gpt2xl_newsgroups = gpt2xl_classifier.predict(\n",
    "    texts=X_test_20news,\n",
    "    task_type='newsgroups',\n",
    "    valid_labels=unique_categories\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "results_gpt2xl_newsgroups = evaluate_classifier(\n",
    "    y_true=y_test_20news,\n",
    "    y_pred=predictions_gpt2xl_newsgroups,\n",
    "    label_names=unique_categories\n",
    ")\n",
    "\n",
    "print_results(results_gpt2xl_newsgroups, \"GPT-2-XL (with preprocessing)\", \"20Newsgroups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Experiment 6: 20Newsgroups with Gemma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running predictions with google/gemma-2-2b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 298/298 [04:24<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Results: Gemma2 (with preprocessing) - 20Newsgroups\n",
      "================================================================================\n",
      "\n",
      "Accuracy: 0.1107\n",
      "\n",
      "Macro Metrics:\n",
      "  Precision: 0.0398\n",
      "  Recall:    0.1100\n",
      "  F1-Score:  0.0464\n",
      "\n",
      "Micro Metrics:\n",
      "  Precision: 0.1107\n",
      "  Recall:    0.1107\n",
      "  F1-Score:  0.1107\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.09      0.27      0.13        15\n",
      "           comp.graphics       0.11      1.00      0.20        15\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00        15\n",
      "comp.sys.ibm.pc.hardware       0.00      0.00      0.00        15\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00        15\n",
      "          comp.windows.x       0.00      0.00      0.00        15\n",
      "            misc.forsale       0.00      0.00      0.00        15\n",
      "               rec.autos       0.00      0.00      0.00        15\n",
      "         rec.motorcycles       0.00      0.00      0.00        14\n",
      "      rec.sport.baseball       0.00      0.00      0.00        15\n",
      "        rec.sport.hockey       0.00      0.00      0.00        15\n",
      "               sci.crypt       0.25      0.20      0.22        15\n",
      "         sci.electronics       0.00      0.00      0.00        15\n",
      "                 sci.med       0.00      0.00      0.00        15\n",
      "               sci.space       0.00      0.00      0.00        15\n",
      "  soc.religion.christian       0.13      0.60      0.21        15\n",
      "      talk.politics.guns       0.22      0.13      0.17        15\n",
      "   talk.politics.mideast       0.00      0.00      0.00        15\n",
      "      talk.politics.misc       0.00      0.00      0.00        14\n",
      "      talk.religion.misc       0.00      0.00      0.00        15\n",
      "\n",
      "                accuracy                           0.11       298\n",
      "               macro avg       0.04      0.11      0.05       298\n",
      "            weighted avg       0.04      0.11      0.05       298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicciones\n",
    "predictions_gemma2_newsgroups = gemma2_classifier.predict(\n",
    "    texts=X_test_20news,\n",
    "    task_type='newsgroups',\n",
    "    valid_labels=unique_categories\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "results_gemma2_newsgroups = evaluate_classifier(\n",
    "    y_true=y_test_20news,\n",
    "    y_pred=predictions_gemma2_newsgroups,\n",
    "    label_names=unique_categories\n",
    ")\n",
    "\n",
    "print_results(results_gemma2_newsgroups, \"Gemma2 (with preprocessing)\", \"20Newsgroups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results comparison and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON (WITH PREPROCESSING)\n",
      "================================================================================\n",
      "          Model Preprocessing         Task  Accuracy  F1 Macro  F1 Micro\n",
      "   GPT-2 (124M) With cleaning    Sentiment  0.512500  0.360525  0.512500\n",
      "GPT-2-XL (1.5B) With cleaning    Sentiment  0.550000  0.440946  0.550000\n",
      "         Gemma2 With cleaning    Sentiment  0.604167  0.553283  0.604167\n",
      "   GPT-2 (124M) With cleaning 20Newsgroups  0.053691  0.011058  0.053691\n",
      "GPT-2-XL (1.5B) With cleaning 20Newsgroups  0.053691  0.010693  0.053691\n",
      "         Gemma2 With cleaning 20Newsgroups  0.110738  0.046380  0.110738\n",
      "\n",
      "Results saved to: results_decoders_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table\n",
    "comparison_data = [\n",
    "    {\n",
    "        'Model': 'GPT-2 (124M)',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': 'Sentiment',\n",
    "        'Accuracy': results_gpt2_sentiment['accuracy'],\n",
    "        'F1 Macro': results_gpt2_sentiment['f1_macro'],\n",
    "        'F1 Micro': results_gpt2_sentiment['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'GPT-2-XL (1.5B)',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': 'Sentiment',\n",
    "        'Accuracy': results_gpt2xl_sentiment['accuracy'],\n",
    "        'F1 Macro': results_gpt2xl_sentiment['f1_macro'],\n",
    "        'F1 Micro': results_gpt2xl_sentiment['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Gemma2',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': 'Sentiment',\n",
    "        'Accuracy': results_gemma2_sentiment['accuracy'],\n",
    "        'F1 Macro': results_gemma2_sentiment['f1_macro'],\n",
    "        'F1 Micro': results_gemma2_sentiment['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'GPT-2 (124M)',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': '20Newsgroups',\n",
    "        'Accuracy': results_gpt2_newsgroups['accuracy'],\n",
    "        'F1 Macro': results_gpt2_newsgroups['f1_macro'],\n",
    "        'F1 Micro': results_gpt2_newsgroups['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'GPT-2-XL (1.5B)',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': '20Newsgroups',\n",
    "        'Accuracy': results_gpt2xl_newsgroups['accuracy'],\n",
    "        'F1 Macro': results_gpt2xl_newsgroups['f1_macro'],\n",
    "        'F1 Micro': results_gpt2xl_newsgroups['f1_micro']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Gemma2',\n",
    "        'Preprocessing': 'With cleaning',\n",
    "        'Task': '20Newsgroups',\n",
    "        'Accuracy': results_gemma2_newsgroups['accuracy'],\n",
    "        'F1 Macro': results_gemma2_newsgroups['f1_macro'],\n",
    "        'F1 Micro': results_gemma2_newsgroups['f1_micro']\n",
    "    }\n",
    "]\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS COMPARISON (WITH PREPROCESSING)\")\n",
    "print(\"=\"*80)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Save\n",
    "df_comparison.to_csv('outputs/results_decoders_preprocessed.csv', index=False)\n",
    "print(\"\\nResults saved to: results_decoders_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show a clear distinction between model performance across tasks and highlight the impact of improved prompting techniques such as few-shot examples. For the sentiment analysis task, all models benefited from the enhanced prompts, with accuracy and F1 scores increasing compared to the baseline. Gemma2 achieved the best overall performance, reaching an accuracy of 0.604 and an F1-Macro of 0.553, outperforming both GPT-2 and GPT-2-XL. This improvement demonstrates that even decoder-only models without fine-tuning can leverage structured instructions and examples to better understand binary sentiment classification.\n",
    "\n",
    "In contrast, the 20Newsgroups task remained challenging for all models. GPT-2 and GPT-2-XL showed almost no improvement over the baseline, and their performance stayed near random levels. Gemma2 exhibited the largest relative gain, doubling its accuracy from ~5% to ~11%, but the absolute performance remains low due to the complexity and high granularity of the 20-class topic classification problem. The slight gains observed across models indicate that prompting with contextual descriptions and few-shot examples can help, but is insufficient for fully capturing the topic distribution in long, noisy, domain-specific texts. \n",
    "\n",
    "Overall, Gemma2 proved to be the strongest model across both tasks, and the experiments confirm that carefully designed prompts meaningfully enhance performance, especially on simpler classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plot saved as: comparison_preprocessed.png\n"
     ]
    }
   ],
   "source": [
    "# Comparative plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Sentiment Analysis\n",
    "sentiment_data = df_comparison[df_comparison['Task'] == 'Sentiment']\n",
    "x_pos = np.arange(len(sentiment_data))\n",
    "axes[0].bar(x_pos - 0.2, sentiment_data['Accuracy'], 0.4, label='Accuracy', alpha=0.8)\n",
    "axes[0].bar(x_pos + 0.2, sentiment_data['F1 Macro'], 0.4, label='F1 Macro', alpha=0.8)\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Sentiment Analysis (with preprocessing)')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(sentiment_data['Model'], rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# 20Newsgroups\n",
    "newsgroups_data = df_comparison[df_comparison['Task'] == '20Newsgroups']\n",
    "x_pos = np.arange(len(newsgroups_data))\n",
    "axes[1].bar(x_pos - 0.2, newsgroups_data['Accuracy'], 0.4, label='Accuracy', alpha=0.8)\n",
    "axes[1].bar(x_pos + 0.2, newsgroups_data['F1 Macro'], 0.4, label='F1 Macro', alpha=0.8)\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('20Newsgroups (with preprocessing)')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(newsgroups_data['Model'], rotation=45, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/comparison_preprocessed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved as: comparison_preprocessed.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-1 (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
